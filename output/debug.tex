%% ==============================================================================
%% template.tex - Template principal para Nota Técnica UnB/CCA/MQC
%% Formatação conforme ABNT NBR 14724:2011 (Trabalhos Acadêmicos)
%% ==============================================================================
%% ESTRUTURA MODULAR COM PARTIALS - arquivos em templates/
%% ==============================================================================

\documentclass[
  12pt,           % Tamanho de fonte padrão ABNT
  a4paper,        % Formato A4
  oneside,        % Impressão em um lado
  article         % Classe article para notas técnicas
]{article}

%% ==============================================================================
%% PREÂMBULO - Pacotes e configurações
%% ==============================================================================
%% ==============================================================================
%% preamble.tex - Partial para preâmbulo LaTeX
%% Pacotes e configurações gerais - Padrão ABNT
%% ==============================================================================

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazilian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{calc}
\newcommand{\real}[1]{#1}

%% ==============================================================================
%% TIPOGRAFIA - Padrão Acadêmico Brasileiro
%% Times New Roman é o padrão ABNT; TeX Gyre Termes é equivalente em LaTeX
%% ==============================================================================
\usepackage{tgtermes}  % Times New Roman equivalente (padrão ABNT)
\usepackage{tgheros}   % Helvética para sans-serif (títulos da capa)
\usepackage{tgcursor}  % Courier para monospace

%% Corpo do texto em Times (serifada) - padrão acadêmico
\renewcommand{\rmdefault}{qtm}  % TeX Gyre Termes
\renewcommand{\sfdefault}{qhv}  % TeX Gyre Heros (para capa)

%% ==============================================================================
%% MARGENS - ABNT NBR 14724:2011
%% Superior e esquerda: 3cm | Inferior e direita: 2cm
%% ==============================================================================
\usepackage[
  a4paper,
  top=3cm,
  bottom=2cm,
  left=3cm,
  right=2cm,
  headheight=14.5pt,
  headsep=0.8cm,
  footskip=1.2cm
]{geometry}

%% ==============================================================================
%% ESPAÇAMENTO - ABNT
%% Texto: 1.5 | Citações longas, notas, referências: simples
%% ==============================================================================
\usepackage{setspace}

%% Cabeçalhos e rodapés
\usepackage{fancyhdr}

%% Formatação de seções
\usepackage{titlesec}

%% Sumário
\usepackage{tocloft}

%% ==============================================================================
%% HYPERLINKS - Configuração acadêmica
%% ==============================================================================
\usepackage[
  colorlinks=true,
  linkcolor=black,
  urlcolor=black,
  citecolor=black,
  bookmarks=true,
  bookmarksnumbered=true,
  bookmarksopen=false,
  pdfdisplaydoctitle=true
]{hyperref}

%% Listas - configuração ABNT
\usepackage{enumitem}
\setlist{nosep, leftmargin=1.25cm}
\setlist[itemize]{label={--}}
\setlist[enumerate]{label={\arabic*.}}

%% Citações
\usepackage{csquotes}

%% ==============================================================================
%% GRÁFICOS E FIGURAS
%% ==============================================================================
\usepackage{graphicx}
\graphicspath{{./images/}{./assets/figures/}{./}}
\usepackage{float}  % Para posicionamento [H]
\usepackage{placeins}  % Para \FloatBarrier

%% Configuração de floats para evitar páginas de floats
\renewcommand{\topfraction}{0.85}
\renewcommand{\bottomfraction}{0.85}
\renewcommand{\textfraction}{0.15}
\renewcommand{\floatpagefraction}{0.7}
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{3}
\setcounter{totalnumber}{6}

%% ==============================================================================
%% TABELAS - Configuração profissional
%% ==============================================================================
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{threeparttable}  % Para notas de rodapé em tabelas
%\usepackage{tabularray}      % Tabelas modernas (estado da arte 2024-2025)
%\UseTblrLibrary{booktabs}    % Integração tabularray + booktabs

%% Espaçamento em tabelas booktabs
\setlength{\heavyrulewidth}{0.08em}
\setlength{\lightrulewidth}{0.05em}
\setlength{\cmidrulewidth}{0.03em}
\setlength{\abovetopsep}{0pt}
\setlength{\belowbottomsep}{0pt}

%% Cores
\usepackage{xcolor}

%% ==============================================================================
%% CONFIGURAÇÕES ADICIONAIS ABNT
%% ==============================================================================

%% Microtype para melhor tipografia
\usepackage{microtype}

%% Indentação do primeiro parágrafo após seção (padrão brasileiro)
\usepackage{indentfirst}

%% Notas de rodapé - numeração contínua
\usepackage[bottom]{footmisc}

%% Caption para figuras e tabelas
\usepackage[font=small, labelfont=bf, labelsep=endash]{caption}

%% ==============================================================================
%% CONTROLE DE QUEBRAS DE PÁGINA
%% ==============================================================================

%% Evitar linhas órfãs e viúvas
\widowpenalty=10000
\clubpenalty=10000

%% Espaçamento de floats
\setlength{\floatsep}{12pt plus 2pt minus 2pt}
\setlength{\textfloatsep}{20pt plus 2pt minus 4pt}
\setlength{\intextsep}{12pt plus 2pt minus 2pt}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{\textbf{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}

%% ==============================================================================
%% DEFINIÇÕES PARA PANDOC
%% ==============================================================================

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Ambiente CSLReferences para Pandoc
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2]
 {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}
 {\par}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\usepackage{natbib}
\bibliographystyle{abntex2-alf}

%% ==============================================================================
%% CONFIGURAÇÕES DE ESPAÇAMENTO - ABNT
%% Corpo do texto: 1.5 | Citações longas, notas, referências: simples
%% ==============================================================================

\setstretch{1.5}                    % Espaçamento entre linhas 1.5
\setlength{\parindent}{1.25cm}      % Recuo de parágrafo: 1,25cm (ABNT)
\setlength{\parskip}{0pt}           % Sem espaço entre parágrafos

%% ==============================================================================
%% FORMATAÇÃO DE SEÇÕES - ABNT NBR 6024:2012
%% ==============================================================================
%% ==============================================================================
%% headings.tex - Partial para formatação de seções
%% Configurações de H1, H2, H3, H4 conforme ABNT NBR 6024:2012
%% ==============================================================================

%% ==============================================================================
%% HIERARQUIA VISUAL ABNT:
%% Seção primária:      MAIÚSCULAS + NEGRITO (destaque máximo)
%% Seção secundária:    MAIÚSCULAS + normal (sem negrito) OU minúsculas + negrito
%% Seção terciária:     Minúsculas + negrito
%% Seção quaternária:   Minúsculas + itálico ou normal
%% ==============================================================================

%% Configuração para quebra de página antes de seções primárias
\newcommand{\sectionbreak}{\clearpage}

%% H1: SEÇÃO PRIMÁRIA - MAIÚSCULAS NEGRITO + QUEBRA DE PÁGINA
%% Espaçamento: 18pt antes, 12pt depois (uma linha em branco equivalente)
\titleformat{\section}
  {\sectionbreak\normalfont\fontsize{12pt}{14pt}\selectfont\bfseries\MakeUppercase}
  {\thesection}
  {0.5em}
  {}
\titlespacing*{\section}{0pt}{0pt}{12pt}

%% H2: SEÇÃO SECUNDÁRIA - Minúsculas + Negrito
%% Destaque menor que H1, mas ainda proeminente
\titleformat{\subsection}
  {\normalfont\fontsize{12pt}{14pt}\selectfont\bfseries}
  {\thesubsection}
  {0.5em}
  {}
\titlespacing*{\subsection}{0pt}{16pt}{10pt}

%% H3: SEÇÃO TERCIÁRIA - Minúsculas + Negrito Itálico
%% Diferenciação sutil em relação a H2
\titleformat{\subsubsection}
  {\normalfont\fontsize{12pt}{14pt}\selectfont\bfseries\itshape}
  {\thesubsubsection}
  {0.5em}
  {}
\titlespacing*{\subsubsection}{0pt}{14pt}{8pt}

%% H4: SEÇÃO QUATERNÁRIA - Normal + Itálico
%% Nível mais baixo de hierarquia
\titleformat{\paragraph}[hang]
  {\normalfont\fontsize{12pt}{14pt}\selectfont\itshape}
  {\theparagraph}
  {0.5em}
  {}
\titlespacing*{\paragraph}{0pt}{12pt}{6pt}
%% ==============================================================================
%% SUMÁRIO - ABNT NBR 6027:2012
%% ==============================================================================
%% ==============================================================================
%% toc.tex - Partial para configuração do sumário
%% Formatação do Table of Contents conforme ABNT NBR 6027:2012
%% ==============================================================================

%% ==============================================================================
%% TÍTULO DO SUMÁRIO - Centralizado, maiúsculas, negrito
%% ==============================================================================
\renewcommand{\cfttoctitlefont}{\hfill\fontsize{12pt}{14pt}\selectfont\bfseries\MakeUppercase}
\renewcommand{\cftaftertoctitle}{\hfill}
\setlength{\cftbeforetoctitleskip}{0pt}
\setlength{\cftaftertoctitleskip}{24pt}  % Espaço após título do sumário

%% ==============================================================================
%% ENTRADAS DO SUMÁRIO - Hierarquia visual consistente
%% ==============================================================================

%% Seções primárias: MAIÚSCULAS + negrito
\renewcommand{\cftsecfont}{\fontsize{12pt}{14pt}\selectfont\bfseries}
\renewcommand{\cftsecpagefont}{\fontsize{12pt}{14pt}\selectfont\bfseries}
\setlength{\cftbeforesecskip}{6pt}  % Espaço antes de seções primárias

%% Seções secundárias: normal
\renewcommand{\cftsubsecfont}{\fontsize{12pt}{14pt}\selectfont}
\renewcommand{\cftsubsecpagefont}{\fontsize{12pt}{14pt}\selectfont}
\setlength{\cftsubsecindent}{0.5cm}  % Indentação

%% Seções terciárias: normal
\renewcommand{\cftsubsubsecfont}{\fontsize{12pt}{14pt}\selectfont}
\renewcommand{\cftsubsubsecpagefont}{\fontsize{12pt}{14pt}\selectfont}
\setlength{\cftsubsubsecindent}{1.0cm}  % Indentação progressiva

%% ==============================================================================
%% LINHAS PONTILHADAS - Conectando título à página
%% ==============================================================================
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\renewcommand{\cftsubsecleader}{\cftdotfill{\cftdotsep}}
\renewcommand{\cftsubsubsecleader}{\cftdotfill{\cftdotsep}}

%% Espaçamento dos pontos
\renewcommand{\cftdotsep}{1.5}
%% ==============================================================================
%% CABEÇALHO E RODAPÉ - ABNT
%% Numeração no canto superior direito ou inferior direito
%% ==============================================================================

\pagestyle{fancy}
\fancyhf{}
\fancyfoot[R]{\fontsize{10pt}{12pt}\selectfont\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

%% ==============================================================================
%% METADADOS
%% ==============================================================================

\title{NOTA TÉCNICA - RECOMENDAÇÃO DE COMPRA DE AÇÃO VIA CAPM}
\date{}

%% ==============================================================================
%% INÍCIO DO DOCUMENTO
%% ==============================================================================

\begin{document}

%% ============================================================================
%% PÁGINA 1: CAPA
%% ============================================================================
%% ==============================================================================
%% titlepage.tex - Partial para capa da Nota Técnica
%% Este arquivo é processado pelo Pandoc - variáveis  são substituídas
%% Formatação seguindo padrões ABNT NBR 14724:2011
%% ==============================================================================

\begin{titlepage}
\thispagestyle{empty}
\setstretch{1.0}

%% ============================================================================
%% BLOCO SUPERIOR - Identificação Institucional
%% ABNT: Nome da instituição em maiúsculas, centralizado
%% ============================================================================

\begin{center}

%% Logo UnB - proporção adequada para identificação visual
\includegraphics[height=2.5cm]{images/logo-unb.png}
\vspace{1cm}

%% Hierarquia institucional - ABNT recomenda maiúsculas para instituição
%% Usando fonte serifada (Times) para formalidade acadêmica
{%
\fontsize{14pt}{18pt}\selectfont
\textbf{UNIVERSIDADE DE BRASÍLIA}\\[0.3cm]
}
{%
\fontsize{12pt}{16pt}\selectfont
\MakeUppercase{Faculdade de Economia, Administração, Contabilidade}\\
\MakeUppercase{e Gestão de Políticas Públicas}\\[0.2cm]
\MakeUppercase{Departamento de Ciências Contábeis e Atuariais}\\[0.4cm]
}

%% Curso
{\fontsize{12pt}{14pt}\selectfont Bacharelado em Ciências Contábeis}

\end{center}

\vspace{1.5cm}

%% ============================================================================
%% IDENTIFICAÇÃO DO DOCUMENTO
%% ============================================================================

\noindent
\begin{tabular*}{\textwidth}{@{}l@{\extracolsep{\fill}}r@{}}
{\fontsize{12pt}{14pt}\selectfont
\textbf{Nota Técnica nº} \_\_\_\_%
/\textit{MQC}}
&
{\fontsize{12pt}{14pt}\selectfont
\textbf{Data:} \_\_\_/\_\_\_/\_\_\_\_\_}
\end{tabular*}

\vspace{2cm}

%% ============================================================================
%% TÍTULO - Elemento central e mais destacado
%% ABNT: Centralizado, negrito, maiúsculas, fonte 12pt ou maior
%% ============================================================================

\begin{center}
{%
\fontsize{14pt}{20pt}\selectfont
\bfseries
\setstretch{1.5}
NOTA TÉCNICA - RECOMENDAÇÃO DE COMPRA DE AÇÃO VIA CAPM
\par
}
\end{center}

\vspace{2cm}

%% ============================================================================
%% INFORMAÇÕES DO TRABALHO - Dados da análise
%% Formatação em bloco para alinhamento visual consistente
%% ============================================================================

\noindent
\fontsize{12pt}{18pt}\selectfont
\setstretch{1.5}

\textbf{Empresa analisada:} \rule{8cm}{0.4pt}

\vspace{0.4cm}

\textbf{Setor:} \rule{10cm}{0.4pt}

\vspace{0.4cm}

\textbf{Período de análise:} \_\_\_\_\_\, a \,\_\_\_\_\_\, (frequência: mensal)

\vspace{2.5cm}

%% ============================================================================
%% AUTORIA - Identificação do(s) autor(es)
%% ABNT: Alinhamento à direita, espaçamento 1.5
%% ============================================================================

\begin{flushright}
\fontsize{12pt}{18pt}\selectfont
\setstretch{1.5}
\textbf{Autor:} \rule{6cm}{0.4pt}
\end{flushright}

\vfill

%% ============================================================================
%% BLOCO INFERIOR - Local e Ano
%% ABNT: Centralizado, última informação da capa
%% ============================================================================

\begin{center}
\fontsize{12pt}{16pt}\selectfont
Brasília -- DF\\[0.3cm]
2025
\end{center}

\end{titlepage}
%% ============================================================================
%% PÁGINA 2: AUTORIDADES
%% ============================================================================
%% ==============================================================================
%% authorities.tex - Partial para página de autoridades
%% Este arquivo é processado pelo Pandoc - variáveis  são substituídas
%% Formatação seguindo padrões acadêmicos institucionais
%% ==============================================================================

\newpage
\thispagestyle{empty}
\setstretch{1.0}

%% Empurra todo o conteúdo para o final da página
\null
\vfill

\begin{center}
\fontsize{11pt}{16pt}\selectfont

{\bfseries Professora Doutora Márcia Abrahão Moura}\\
{\small Reitora da Universidade de Brasília}

\vspace{0.7cm}

{\bfseries Professor Doutor Enrique Huelva Unternbäumen}\\
{\small Vice-Reitor da Universidade de Brasília}

\vspace{0.7cm}

{\bfseries Professor Doutor Sérgio Antônio Andrade de Freitas}\\
{\small Decano de Ensino de Graduação}

\vspace{0.7cm}

{\bfseries Professor Doutor Eduardo Tadeu Vieira}\\
{\small Diretor da Faculdade de Economia, Administração, Contabilidade}\\
{\small e Gestão de Políticas Públicas}

\vspace{0.7cm}

{\bfseries Professor Doutor Paulo César de Melo Mendes}\\
{\small Chefe do Departamento de Ciências Contábeis e Atuariais}

\vspace{0.7cm}

{\bfseries Professor Doutor Alex Laquis Resende}\\
{\small Coordenador de Graduação do curso de Ciências Contábeis – Diurno}

\vspace{0.7cm}

{\bfseries Professor Mestre Elivânio Geraldo de Andrade}\\
{\small Coordenador de Graduação do curso de Ciências Contábeis – Noturno}

\end{center}

\vspace{1.5cm}
%% --------------------------------------------------------------------------
%% SUMÁRIO
%% --------------------------------------------------------------------------
\newpage
\tableofcontents

%% --------------------------------------------------------------------------
%% LISTA DE FIGURAS
%% --------------------------------------------------------------------------
\newpage
\listoffigures

%% --------------------------------------------------------------------------
%% LISTA DE TABELAS
%% --------------------------------------------------------------------------
\newpage
\listoftables

%% --------------------------------------------------------------------------
%% LISTA DE ABREVIATURAS E SIGLAS
%% --------------------------------------------------------------------------
\newpage
\begin{center}
{\large\bfseries LISTA DE ABREVIATURAS E SIGLAS}
\end{center}
\vspace{0.5cm}
\begin{flushleft}
\textbf{CAPM} \hspace{0.5cm} Capital Asset Pricing Model (Modelo de
Precificação de Ativos de Capital) \\[0.3cm]
\textbf{ICC} \hspace{0.5cm} Implied Cost of Capital (Custo de Capital
Implícito) \\[0.3cm]
\textbf{DDM} \hspace{0.5cm} Dividend Discount Model (Modelo de Desconto
de Dividendos) \\[0.3cm]
\textbf{EV} \hspace{0.5cm} Enterprise Value (Valor da Empresa) \\[0.3cm]
\textbf{EBITDA} \hspace{0.5cm} Earnings Before Interest, Taxes,
Depreciation and Amortization \\[0.3cm]
\textbf{EVS} \hspace{0.5cm} Economic Value Spread (Spread de Valor
Econômico) \\[0.3cm]
\textbf{P/L} \hspace{0.5cm} Preço/Lucro \\[0.3cm]
\textbf{P/VP} \hspace{0.5cm} Preço/Valor Patrimonial \\[0.3cm]
\textbf{ROE} \hspace{0.5cm} Return on Equity (Retorno sobre Patrimônio
Líquido) \\[0.3cm]
\textbf{ROACE} \hspace{0.5cm} Return on Average Capital Employed
(Retorno sobre Capital Empregado Médio) \\[0.3cm]
\textbf{WACC} \hspace{0.5cm} Weighted Average Cost of Capital (Custo
Médio Ponderado de Capital) \\[0.3cm]
\textbf{ERP} \hspace{0.5cm} Equity Risk Premium (Prêmio de Risco de
Mercado) \\[0.3cm]
\textbf{SML} \hspace{0.5cm} Security Market Line (Linha de Mercado de
Títulos) \\[0.3cm]
\textbf{OLS} \hspace{0.5cm} Ordinary Least Squares (Mínimos Quadrados
Ordinários) \\[0.3cm]
\textbf{bps} \hspace{0.5cm} Basis Points (Pontos-base) \\[0.3cm]
\end{flushleft}

%% --------------------------------------------------------------------------
%% RESUMO
%% --------------------------------------------------------------------------
\newpage
\begin{center}
{\large\bfseries RESUMO}
\end{center}
\vspace{0.5cm}
\noindent
Este trabalho desenvolve motor de scoring quantitativo (Q-VAL) para
análise de comprabilidade de ativos, aplicando-o à Petrobras S.A.
(PETR4) no contexto da autorização de exploração da Margem Equatorial
brasileira. O modelo integra métricas de Valor, Qualidade e Risco,
fundamentando-se no Capital Asset Pricing Model (CAPM) para estimação do
custo de capital próprio. A partir de 2.462 observações diárias
(2016--2025), estima-se beta de 1,40 e custo de capital de 16,60\%. Os
resultados indicam score Q-VAL de 53,4 (faixa Neutra), com spread
ICC-CAPM de +40 basis points, sugerindo precificação justa. A análise de
cenários revela alta sensibilidade às premissas sobre preço do Brent e
sucesso da Margem Equatorial, com scores variando de 43,0 (Venda) a 62,8
(Compra). Conclui-se que PETR4 não configura oportunidade clara de
compra nem armadilha de valor evidente, com recomendação condicional ao
perfil de risco e horizonte de investimento.

\vspace{0.5cm}
\noindent\textbf{Palavras-chave:} CAPM; Valuation; Scoring
Fundamentalista; Petrobras; Margem Equatorial; Custo de Capital
Implícito.

%% --------------------------------------------------------------------------
%% EPÍGRAFE
%% --------------------------------------------------------------------------
\newpage
\vspace*{\fill}
\begin{flushright}
\begin{minipage}{0.6\textwidth}
\raggedleft
\textit{``Price is what you pay. Value is what you get.''}

\vspace{0.3cm}
--- Warren Buffett
\end{minipage}
\end{flushright}
\vspace*{\fill}

%% --------------------------------------------------------------------------
%% CONTEÚDO PRINCIPAL
%% --------------------------------------------------------------------------
\newpage
\setstretch{1.5}

\hypertarget{introduuxe7uxe3o}{%
\section{Introdução}\label{introduuxe7uxe3o}}

A pergunta sobre como mercados processam informação atravessa a história
do pensamento econômico como questão simultaneamente técnica,
epistemológica e filosófica. Técnica porque demanda modelos formais
capazes de capturar a relação entre informação disponível e formação de
preços. Epistemológica porque interroga os limites do conhecimento
possível em sistemas descentralizados onde nenhum agente possui visão
completa do todo. Filosófica porque implica juízos sobre racionalidade,
eficiência e os fundamentos normativos da organização econômica. Este
trabalho situa-se na interseção dessas dimensões, propondo investigação
empírica de uma questão teórica fundamental: em que medida a análise
fundamentalista estruturada adiciona informação ao processo de
precificação de ativos, ou apenas replica conhecimento já incorporado
pelo mecanismo de mercado?

A tradição intelectual que informa esta investigação remonta ao ensaio
seminal de Hayek (1945), onde o sistema de preços é caracterizado como
``maravilha'' epistêmica --- mecanismo de telecomunicação que condensa
informações dispersas e tácitas, o ``conhecimento das circunstâncias
particulares de tempo e lugar'', que nenhum agente central poderia
reunir. Para Hayek, o mercado resolve problema computacional de
complexidade intratável: agregar bilhões de fragmentos de conhecimento
local em sinais de preço que coordenam decisões descentralizadas. A
intuição hayekiana foi posteriormente formalizada por Fama (1970) na
Hipótese dos Mercados Eficientes (EMH), segundo a qual os preços
refletem toda informação disponível, tornando impossível a obtenção
sistemática de retornos anormais através de análise de dados públicos.

Contudo, a elegância teórica da EMH encontra obstáculo lógico
identificado por Grossman; Stiglitz (1980): se os preços refletissem
perfeitamente toda informação, não haveria incentivo para incorrer nos
custos de sua coleta e processamento. O paradoxo de Grossman-Stiglitz
estabelece que mercados perfeitamente eficientes são impossíveis ---
algum grau de ineficiência é necessário para compensar o custo da
informação e garantir que agentes continuem a produzi-la. Este teorema
fundamenta teoricamente a existência da análise fundamentalista:
analistas calculam métricas, constroem modelos e emitem recomendações
porque esperam ser compensados por esse esforço através de retornos
superiores ao mercado.

Desenvolvimentos recentes oferecem enquadramentos complementares. A
Hipótese dos Mercados Adaptativos de Lo (2004), formalizada em Lo; Zhang
(2024), reconcilia eficiência e comportamento através de lente
evolucionária: mercados não são eficientes \emph{ou} ineficientes, mas
\emph{adaptativos}. A eficiência varia ao longo do tempo, dependendo do
ambiente competitivo, da densidade de participantes informados, e da
disponibilidade de oportunidades de arbitragem. Métricas
fundamentalistas, nessa perspectiva, são estratégias adaptativas que
funcionam em certos regimes e desaparecem quando o mercado se adapta a
elas. A economia da complexidade, desenvolvida no Santa Fe Institute por
Arthur (2014) e sintetizada em Arthur (2021), oferece enquadramento
ainda mais radical: mercados são sistemas adaptativos complexos onde
agentes heterogêneos com racionalidade limitada interagem em redes,
produzindo dinâmicas emergentes não redutíveis a equilíbrio. Nessa
visão, informação não é simplesmente ``refletida'' nos preços --- é
criada, disseminada, distorcida e amplificada em processos que podem
incluir herding, cascatas informacionais e bolhas.

A contribuição pós-hayekiana de Colin-Jaeger; Delcey (2020) elucida
tensão metodológica entre tradições: enquanto Hayek concebia preços como
sinais dentro de processo dinâmico de competição, onde conhecimento
relevante é tácito e processual, a EMH de Fama trata preços como
reflexos de informação em equilíbrio, onde conhecimento é proposicional
e agregável. O trabalho de Kuchar (2025) estende a perspectiva hayekiana
para ciência cognitiva, propondo que mercados sejam entendidos como
redes de cognição socialmente estendida --- não apenas mecanismos de
alocação, mas sistemas de aprendizado coletivo onde preferências e
conhecimento são formados, não apenas revelados. A implicação para
análise fundamentalista é profunda: métricas não apenas ``medem''
fundamentos --- participam do processo cognitivo coletivo que forma
preços, podendo tornar-se profecias autorrealizáveis ou autofrustrantes.

A pergunta central que orienta esta investigação pode ser formulada nos
seguintes termos: considerando a Petrobras S.A. (PETR4) como caso
empírico, em contexto de expansão para novas fronteiras exploratórias e
riscos ESG/regulatórios associados, o acréscimo de informação
fundamentalista estruturada --- operacionalizada através de motor de
\emph{scoring} multidimensional --- resulta em aumento mensurável da
capacidade explicativa sobre retornos? Formalmente: o \(\Delta R^2\)
entre modelo de mercado puro (CAPM) e modelo acrescido de métricas
fundamentalistas é estatisticamente significativo e economicamente
relevante?

A relevância do caso Petrobras transcende o interesse específico no
ativo. Trata-se da maior empresa brasileira por capitalização de
mercado, componente dominante do índice Ibovespa, e objeto de cobertura
analítica intensa --- dezenas de relatórios de \emph{sell-side},
vigilância permanente de mídia especializada, dados públicos abundantes
via CVM e B3. Se algum ativo deveria estar ``perfeitamente precificado''
no mercado brasileiro, seria este. Paradoxalmente, a empresa exibe
características que podem gerar fricções informacionais: assimetria
entre gestão e investidores, complexidade contábil do setor de óleo e
gás, interferência estatal recorrente, e --- no momento presente ---
incerteza binária sobre o desfecho da exploração da Margem Equatorial. A
tensão entre alta cobertura analítica e potencial persistência de
mispricings torna PETR4 laboratório ideal para testar a contribuição
marginal da análise fundamentalista.

Do ponto de vista metodológico, a abordagem proposta operacionaliza
conceitos teóricos abstratos em testes empíricos. O motor Q-VAL,
desenvolvido como instrumento de análise multidimensional integrando
métricas de Valor, Qualidade e Risco, serve como proxy para o ``custo da
informação'' no sentido de Grossman-Stiglitz: representa esforço
sistemático de coleta, processamento e síntese de dados
fundamentalistas. A comparação entre modelos econométricos progressivos
--- do CAPM puro ao modelo acrescido do score Q-VAL --- permite
quantificar o ``retorno'' desse investimento informacional via variação
explicada (\(\Delta R^2\)). A análise é complementada por critérios de
informação (AIC, BIC) que penalizam complexidade, respondendo à pergunta
crucial: o motor de métricas está adicionando sinal ou apenas ruído?

O trabalho estrutura-se em cinco movimentos. Primeiro, estabelece
fundamentos teóricos sobre o sistema de preços como mecanismo
informacional, revisando a tradição hayekiana, a EMH, o paradoxo de
Grossman-Stiglitz, e desenvolvimentos contemporâneos em mercados
adaptativos e economia da complexidade. Segundo, contextualiza o caso
Petrobras no momento presente --- a autorização de exploração da Margem
Equatorial e suas implicações para valuation. Terceiro, descreve a
metodologia, incluindo o motor Q-VAL, os modelos econométricos
comparativos, e as métricas de avaliação informacional. Quarto,
apresenta resultados empíricos --- estimação CAPM, score de
comprabilidade, e análise de contribuição informacional. Quinto, discute
implicações teóricas e práticas, situando os achados no debate sobre
eficiência de mercado e o papel da análise fundamentalista.

Os objetivos específicos deste trabalho são:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimar o custo de capital próprio de PETR4 via CAPM, estabelecendo
  baseline de explicação por informação de preço;
\item
  Calcular métricas fundamentalistas organizadas nas dimensões de Valor,
  Qualidade e Risco;
\item
  Desenvolver motor de \emph{scoring} Q-VAL integrando as três dimensões
  em índice sintético;
\item
  Quantificar a contribuição informacional marginal das métricas via
  análise de \(\Delta R^2\) e critérios de informação;
\item
  Diagnosticar \emph{mispricing} via comparação entre Implied Cost of
  Capital e custo teórico;
\item
  Analisar cenários (base, otimista, pessimista) e sensibilidade do
  score a variações nas premissas;
\item
  Discutir implicações dos resultados para a teoria de eficiência de
  mercado e a prática de análise fundamentalista.
\end{enumerate}

A hipótese subjacente --- de que métricas fundamentalistas adicionam
informação não plenamente capturada pelo mecanismo de preços ---
encontra fundamento teórico no paradoxo de Grossman-Stiglitz e
sustentação empírica na literatura de anomalias de mercado e prêmios de
fatores. Contudo, a magnitude e persistência dessa contribuição são
questões empíricas que dependem do contexto institucional, da densidade
de cobertura analítica, e do regime de mercado vigente. O caso Petrobras
oferece oportunidade de testar essas proposições em ambiente de alta
densidade informacional e incerteza estrutural sobre cenários futuros
--- combinação que torna particularmente relevante a pergunta sobre o
valor marginal da análise fundamentalista sistemática.

\hypertarget{fundamentos-teuxf3ricos}{%
\section{Fundamentos Teóricos}\label{fundamentos-teuxf3ricos}}

\hypertarget{o-sistema-de-preuxe7os-como-mecanismo-informacional}{%
\subsection{O Sistema de Preços como Mecanismo
Informacional}\label{o-sistema-de-preuxe7os-como-mecanismo-informacional}}

A compreensão do mercado financeiro como sistema de processamento de
informação constitui uma das contribuições mais profundas da teoria
econômica do século XX. A tradição intelectual que informa esta
perspectiva remonta ao debate sobre cálculo econômico sob o socialismo,
travado nas décadas de 1920 e 1930, onde a questão central era se um
planejador central poderia, em princípio, replicar a eficiência
alocativa de mercados descentralizados. A resposta negativa, articulada
com maior rigor por Friedrich August von Hayek, transcendeu o debate
original para estabelecer fundamentos epistemológicos que permanecem
centrais à teoria financeira contemporânea.

\hypertarget{a-contribuiuxe7uxe3o-hayekiana-conhecimento-disperso-e-coordenauxe7uxe3o}{%
\subsubsection{A Contribuição Hayekiana: Conhecimento Disperso e
Coordenação}\label{a-contribuiuxe7uxe3o-hayekiana-conhecimento-disperso-e-coordenauxe7uxe3o}}

O ensaio seminal de Hayek (1945) reformula o problema econômico
fundamental. A questão não é, como supunham economistas anteriores, a
alocação ótima de recursos \emph{dados} --- problema que, em princípio,
admite solução técnica via programação linear ou métodos equivalentes. O
problema genuíno é a utilização de conhecimento que \emph{não está dado}
a ninguém em sua totalidade. O conhecimento relevante para decisões
econômicas encontra-se disperso entre milhões de agentes, cada qual
possuindo fragmentos únicos --- ``conhecimento das circunstâncias
particulares de tempo e lugar'' --- que nenhum mecanismo centralizador
poderia reunir.

Esta dispersão não é acidental, mas constitutiva da realidade econômica.
O comerciante local conhece o estado de seus estoques, as preferências
idiossincráticas de seus clientes, as condições de suas instalações. O
transportador conhece capacidades ociosas, rotas alternativas, condições
de tráfego. O especulador conhece rumores, padrões históricos,
correlações sutis. Cada fragmento de conhecimento é tácito, contextual e
frequentemente inarticulável --- o que Michael Polanyi denominaria
posteriormente \emph{tacit knowledge}, distinguindo-o do conhecimento
proposicional formalizável.

O sistema de preços emerge, nesta perspectiva, como solução evolutiva
para o problema de coordenação sob dispersão informacional. Hayek
caracteriza-o como ``maravilha'' epistêmica:

\begin{quote}
``O aspecto mais significativo deste sistema é a economia de
conhecimento com que opera, ou quão pouco os participantes individuais
precisam saber para tomar a ação correta. Em forma abreviada, por uma
espécie de símbolo, apenas a informação mais essencial é transmitida.''
(Hayek, 1945, p. 527)
\end{quote}

O preço funciona como \emph{estatística suficiente} --- no sentido
técnico do termo --- condensando em um único número toda a informação
relevante para a decisão marginal. O agente não precisa conhecer as
causas que alteraram condições de oferta e demanda em mercados
distantes; basta observar a variação de preços para ajustar seu
comportamento de modo coordenado com milhões de outros agentes que
também respondem ao mesmo sinal.

\hypertarget{do-conhecimento-tuxe1cito-ao-conhecimento-proposicional}{%
\subsubsection{Do Conhecimento Tácito ao Conhecimento
Proposicional}\label{do-conhecimento-tuxe1cito-ao-conhecimento-proposicional}}

A transição da intuição hayekiana para modelos formais de finanças
envolve transformação epistemológica significativa. Para Hayek, o
conhecimento relevante é fundamentalmente \emph{processual} e
\emph{tácito} --- emerge no processo competitivo e não pode ser
plenamente articulado fora dele. A formalização subsequente, culminando
na Hipótese dos Mercados Eficientes, tratou conhecimento como
\emph{proposicional} e \emph{agregável} --- conjunto de proposições
verdadeiras que podem, em princípio, ser listadas e incorporadas a
modelos.

Colin-Jaeger; Delcey (2020) analisam esta transformação com rigor
historiográfico. A EMH, argumentam, operacionalizou intuições hayekianas
em forma testável, mas ao fazê-lo perdeu dimensões essenciais. Onde
Hayek via processo dinâmico de descoberta --- competição como
procedimento de exploração do desconhecido ---, Fama vê equilíbrio
estático onde toda informação já foi descoberta e incorporada. A tensão
entre estas concepções não é meramente acadêmica; implica visões
distintas sobre a possibilidade e utilidade da análise fundamentalista.

A implicação para o presente trabalho é direta. Se conhecimento
relevante é proposicional e já incorporado aos preços (Fama), métricas
fundamentalistas não deveriam adicionar poder explicativo. Se
conhecimento é processual e parcialmente tácito (Hayek), métricas podem
capturar dimensões que o mercado ainda não processou --- ou que processa
com defasagem, ruído ou viés.

\hypertarget{mercados-como-processadores-de-informauxe7uxe3o}{%
\subsubsection{Mercados como Processadores de
Informação}\label{mercados-como-processadores-de-informauxe7uxe3o}}

A metáfora computacional oferece enquadramento complementar. Mercados
podem ser entendidos como sistemas distribuídos de processamento de
informação, onde agentes individuais funcionam como processadores locais
que recebem sinais (preços, notícias, dados), executam algoritmos
(heurísticas, modelos, intuições) e produzem outputs (ordens de compra e
venda) que, agregados, geram novos sinais para o sistema.

Esta perspectiva ilumina tanto a potência quanto as limitações do
mecanismo de preços. Como sistema de computação distribuída, o mercado
pode processar volumes de informação que excederiam a capacidade de
qualquer agente central. A redundância --- milhões de agentes
processando informações parcialmente sobrepostas --- confere robustez:
erros individuais tendem a se cancelar, e o sinal agregado emerge com
ruído reduzido. O paralelismo permite resposta rápida a novos dados, com
ajustes de preço ocorrendo em milissegundos nos mercados contemporâneos.

Contudo, sistemas distribuídos são vulneráveis a falhas de coordenação.
Comportamento de manada (\emph{herding}) pode amplificar ruído em vez de
filtrá-lo. Cascatas informacionais --- onde agentes racionalmente
ignoram informação privada para seguir o comportamento observado de
outros --- podem propagar erros sistematicamente. Bolhas especulativas
emergem quando o próprio aumento de preços é interpretado como sinal
informativo, gerando feedback positivo que desacopla preços de
fundamentos.

A literatura sobre microestrutura de mercados, iniciada por Glosten;
Milgrom (1985) e desenvolvida por Kyle (1989), formaliza como informação
é incorporada aos preços através do processo de negociação. O
\emph{spread} bid-ask reflete, em parte, o custo que formadores de
mercado incorrem ao negociar com agentes potencialmente informados. A
velocidade de incorporação de informação depende da liquidez, da
densidade de participantes informados, e da estrutura do mercado. Estas
fricções microestruturais implicam que a incorporação de informação é
processo gradual, não instantâneo --- abrindo espaço para que análise
fundamentalista capture informação ainda não plenamente refletida nos
preços.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{eficiuxeancia-de-mercado-da-emh-aos-mercados-adaptativos}{%
\subsection{Eficiência de Mercado: Da EMH aos Mercados
Adaptativos}\label{eficiuxeancia-de-mercado-da-emh-aos-mercados-adaptativos}}

\hypertarget{a-hipuxf3tese-dos-mercados-eficientes-formulauxe7uxe3o-e-taxonomia}{%
\subsubsection{A Hipótese dos Mercados Eficientes: Formulação e
Taxonomia}\label{a-hipuxf3tese-dos-mercados-eficientes-formulauxe7uxe3o-e-taxonomia}}

A formalização da intuição hayekiana em teoria testável deve-se
primordialmente a Eugene Fama, cuja tese de doutorado e trabalhos
subsequentes estabeleceram o paradigma dominante em finanças acadêmicas
por décadas. A Hipótese dos Mercados Eficientes, articulada em Fama
(1970), postula que preços de ativos refletem toda informação relevante
disponível, tornando impossível a obtenção sistemática de retornos
anormais --- retornos superiores ao que seria justificado pelo risco
assumido.

Formalmente, um mercado é eficiente com respeito a um conjunto de
informações \(\Phi_t\) se é impossível obter lucros econômicos
negociando com base em \(\Phi_t\). Isto implica que:

\[E[R_{t+1} | \Phi_t] = E[R_{t+1}]\]

onde \(R_{t+1}\) denota o retorno do ativo no período seguinte. A
expectativa condicional ao conjunto de informações iguala a expectativa
incondicional --- conhecer \(\Phi_t\) não permite previsão superior à
que seria obtida ignorando essa informação.

Fama propôs taxonomia tripartite baseada na amplitude do conjunto
informacional:

\textbf{Eficiência na Forma Fraca:} O conjunto \(\Phi_t\) inclui apenas
o histórico de preços e retornos passados. Eficiência nesta forma
implica que análise técnica --- estratégias baseadas em padrões de
preços históricos --- não pode gerar retornos anormais sistematicamente.
Padrões como ``cabeça e ombros'', médias móveis ou indicadores de
momentum não teriam poder preditivo além do acaso.

\textbf{Eficiência na Forma Semi-Forte:} O conjunto \(\Phi_t\) inclui
toda informação publicamente disponível --- demonstrações financeiras,
comunicados ao mercado, dados macroeconômicos, notícias. Eficiência
nesta forma implica que análise fundamentalista --- estratégias baseadas
em avaliação de fundamentos econômicos --- não pode gerar retornos
anormais. Múltiplos como P/L, P/VP, EV/EBITDA, ou métricas de qualidade
como ROE e ROIC, sendo públicos, já estariam incorporados aos preços.

\textbf{Eficiência na Forma Forte:} O conjunto \(\Phi_t\) inclui toda
informação, pública e privada. Eficiência nesta forma implica que nem
mesmo \emph{insiders} com acesso privilegiado poderiam obter retornos
anormais. Esta forma é geralmente rejeitada empiricamente, dado que
estudos documentam retornos anormais em negociações de insiders (Jaffe,
1974).

\hypertarget{eviduxeancia-empuxedrica-anomalias-e-pruxeamios-de-fatores}{%
\subsubsection{Evidência Empírica: Anomalias e Prêmios de
Fatores}\label{eviduxeancia-empuxedrica-anomalias-e-pruxeamios-de-fatores}}

A elegância teórica da EMH confrontou-se, desde o início, com evidência
empírica de anomalias --- padrões de retorno aparentemente previsíveis
que persistem ao longo do tempo e através de mercados. O programa de
pesquisa em anomalias de mercado constitui um dos mais extensos da
literatura financeira, documentando centenas de variáveis com aparente
poder preditivo sobre retornos.

Fama (1998) oferece defesa sofisticada da EMH frente às anomalias.
Argumenta que aparentes retornos anormais frequentemente (i) desaparecem
quando custos de transação realistas são considerados, (ii) são
artefatos de \emph{data snooping} --- pesquisadores testando múltiplas
hipóteses até encontrar significância estatística ---, ou (iii)
representam compensação por risco não capturado pelo modelo de
precificação utilizado.

O terceiro argumento é particularmente relevante para o presente
trabalho. Se o CAPM unifatorial é especificação incompleta --- se
existem fatores de risco sistemático além do mercado ---, então o que
parece ``alfa'' (retorno anormal) pode ser apenas ``beta'' (compensação
por risco) em dimensão não modelada. Esta lógica motivou a extensão do
CAPM para modelos multifatoriais.

Fama; French (1993) propuseram modelo trifatorial, adicionando ao fator
de mercado dois fatores empiricamente motivados: SMB (\emph{Small Minus
Big}), capturando o prêmio de tamanho --- empresas pequenas tendem a
gerar retornos superiores ---, e HML (\emph{High Minus Low}), capturando
o prêmio de valor --- empresas com alto índice book-to-market tendem a
superar aquelas com baixo índice. O modelo explica parcela substancial
da variação transversal de retornos que o CAPM deixava inexplicada.

Extensões subsequentes adicionaram fatores de momentum (Jegadeesh;
Titman, 1993), lucratividade e investimento (Fama; French, 2015), e
qualidade (Asness; Frazzini; Pedersen, 2019a). O modelo de cinco fatores
de Fama-French representa, atualmente, especificação padrão para
controle de risco em estudos de anomalias:

\[R_{i,t} - R_{f,t} = \alpha_i + \beta_{i,MKT}(R_{m,t} - R_{f,t}) + \beta_{i,SMB}SMB_t + \beta_{i,HML}HML_t + \beta_{i,RMW}RMW_t + \beta_{i,CMA}CMA_t + \varepsilon_{i,t}\]

onde \(RMW\) (\emph{Robust Minus Weak}) captura o prêmio de
lucratividade e \(CMA\) (\emph{Conservative Minus Aggressive}) captura o
prêmio de conservadorismo em investimentos.

A proliferação de fatores gerou preocupação com \emph{overfitting}.
Harvey; Liu; Zhu (2016) documentam mais de 300 fatores publicados na
literatura acadêmica --- o ``zoológico de fatores'' --- e argumentam que
a maioria representa artefatos estatísticos. Propõem ajuste de múltiplos
testes via controle de \emph{false discovery rate}, elevando
substancialmente o limiar para significância estatística.

\hypertarget{a-hipuxf3tese-dos-mercados-adaptativos}{%
\subsubsection{A Hipótese dos Mercados
Adaptativos}\label{a-hipuxf3tese-dos-mercados-adaptativos}}

A tensão entre eficiência teórica e anomalias empíricas motivou
formulações alternativas. A contribuição mais influente é a Hipótese dos
Mercados Adaptativos (AMH), proposta por Lo (2004) e formalizada
extensivamente em Lo; Zhang (2024).

A AMH reconcilia eficiência e comportamento através de lente
evolucionária. Mercados não são eficientes \emph{ou} ineficientes de
modo binário e atemporal; são \emph{adaptativos}, exibindo graus
variáveis de eficiência dependendo do ambiente competitivo, da densidade
de participantes, e da disponibilidade de oportunidades de arbitragem. A
metáfora central é ecológica: mercados são ecossistemas onde
``espécies'' de estratégias competem por recursos (retornos), com
populações expandindo quando estratégias são lucrativas e contraindo
quando deixam de sê-lo.

Formalmente, Lo propõe que agentes econômicos comportam-se de acordo com
princípios evolucionários: agem em interesse próprio, cometem erros,
aprendem e se adaptam, competem por recursos, e estão sujeitos a seleção
natural. Estas premissas substituem as do \emph{homo economicus}
neoclássico --- racionalidade perfeita, informação completa,
preferências estáveis --- por descrição mais consonante com evidência de
psicologia cognitiva e neurociência.

As implicações diferem substancialmente da EMH:

\textbf{Eficiência é contexto-dependente:} Em mercados líquidos com alta
densidade de participantes sofisticados (ações de grande capitalização
em bolsas desenvolvidas), eficiência tende a ser elevada. Em mercados
ilíquidos com poucos participantes (small caps em mercados emergentes,
ativos alternativos), ineficiências podem persistir.

\textbf{Prêmios de risco variam no tempo:} A compensação exigida por
diferentes tipos de risco flutua com condições de mercado, densidade de
capital alocado à estratégia, e memória recente de eventos extremos. O
prêmio de valor, por exemplo, pode ser elevado em períodos de aversão ao
risco e comprimido quando capital abundante persegue a estratégia.

\textbf{Estratégias têm ``meia-vida'':} Anomalias descobertas tendem a
desaparecer conforme participantes ajustam comportamento em resposta à
informação. A publicação acadêmica de uma anomalia pode, paradoxalmente,
eliminar sua lucratividade --- fenômeno documentado por McLean; Pontiff
(2016).

\textbf{Inovação cria novas oportunidades:} Mudanças estruturais ---
novos instrumentos, novas tecnologias, novos regulamentos --- criam
nichos ecológicos onde ineficiências temporárias emergem antes que o
mercado se adapte.

Hirshleifer; Lo; Zhang (2023) estendem a análise para incluir dinâmicas
de contágio social. Demonstram que vieses comportamentais não
necessariamente desaparecem sob pressão competitiva; podem, ao
contrário, persistir e até se amplificar quando transmitidos
socialmente. A diversidade de estilos de investimento --- valor,
crescimento, momentum, qualidade --- coexiste porque diferentes
estratégias exploram nichos distintos, com desempenho relativo variando
ciclicamente.

\hypertarget{implicauxe7uxf5es-para-anuxe1lise-fundamentalista}{%
\subsubsection{Implicações para Análise
Fundamentalista}\label{implicauxe7uxf5es-para-anuxe1lise-fundamentalista}}

A transição da EMH para a AMH altera substantivamente as expectativas
sobre análise fundamentalista. Sob a EMH estrita (forma semi-forte),
métricas fundamentalistas públicas não deveriam ter poder preditivo ---
se P/L baixo previsse retornos superiores, arbitradores comprariam ações
baratas até eliminar o spread. A persistência do \emph{value premium}
por décadas representaria, nesta visão, compensação por risco não
modelado.

Sob a AMH, métricas fundamentalistas podem ter poder preditivo variável:

\begin{itemize}
\tightlist
\item
  Em certos regimes (recessões, crises de crédito), quando aversão ao
  risco é elevada e capital é escasso, o prêmio de valor pode ser
  substancial.
\item
  Em outros regimes (expansões, abundância de liquidez), quando capital
  abundante persegue a estratégia, o prêmio pode comprimir-se ou
  inverter-se.
\item
  A descoberta e popularização de uma métrica (via publicação acadêmica
  ou adoção por gestores quantitativos) pode erodir sua eficácia.
\end{itemize}

O motor Q-VAL, neste enquadramento, não é tentativa de arbitrar
ineficiência permanente, mas instrumento para capturar ineficiência
transitória --- explorando, no jargão ecológico, nicho que pode existir
no mercado brasileiro de ações em determinado regime. A análise empírica
subsequente deve, portanto, considerar não apenas o poder preditivo
médio, mas sua variação ao longo do período amostral.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{o-paradoxo-de-grossman-stiglitz-e-o-custo-da-informauxe7uxe3o}{%
\subsection{O Paradoxo de Grossman-Stiglitz e o Custo da
Informação}\label{o-paradoxo-de-grossman-stiglitz-e-o-custo-da-informauxe7uxe3o}}

\hypertarget{o-teorema-de-impossibilidade}{%
\subsubsection{O Teorema de
Impossibilidade}\label{o-teorema-de-impossibilidade}}

Se a EMH fosse literalmente verdadeira --- se preços refletissem
instantânea e perfeitamente toda informação disponível ---, um paradoxo
lógico emergiria. A incorporação de informação aos preços não é processo
espontâneo; requer que agentes incorram em custos para coletar,
processar e agir sobre informação. Analistas fundamentalistas dedicam
recursos substanciais a examinar demonstrações financeiras, conduzir due
diligence, e construir modelos de valuation. Gestores quantitativos
investem em infraestrutura computacional, bases de dados, e talento
técnico. Se toda essa informação já estivesse refletida nos preços, tais
investimentos seriam desperdício --- seus retornos seriam nulos.

Mas se ninguém investisse em coleta de informação --- racionalmente
antecipando retornos nulos ---, como a informação seria incorporada aos
preços? O paradoxo foi formalizado por Grossman; Stiglitz (1980) em
teorema que permanece central à teoria financeira:

\begin{quote}
``Como não poderia haver lucros na coleta de informação, deveria haver
pouco motivo para negociar e pouco motivo para que mercados existissem.
Demonstramos que quando a obtenção de informação é custosa, os preços
não podem refletir perfeitamente a informação disponível, pois se assim
fosse, aqueles que gastaram recursos para obtê-la não receberiam
compensação.'' (Grossman; Stiglitz, 1980, p. 405)
\end{quote}

O teorema estabelece que mercados perfeitamente eficientes são
logicamente impossíveis quando informação é custosa. Algum grau de
ineficiência --- algum retorno anormal para agentes informados --- é
necessário para compensar o custo da informação e garantir que o
processo de incorporação continue operando.

\hypertarget{formalizauxe7uxe3o-equiluxedbrio-com-ruuxeddo}{%
\subsubsection{Formalização: Equilíbrio com
Ruído}\label{formalizauxe7uxe3o-equiluxedbrio-com-ruuxeddo}}

Grossman e Stiglitz formalizam o argumento em modelo de equilíbrio com
dois tipos de agentes: informados (que incorreram no custo \(c\) para
adquirir informação) e desinformados (que observam apenas o preço). Em
equilíbrio, a fração de agentes informados ajusta-se de modo que o
retorno esperado de se tornar informado --- o alfa esperado --- iguale
exatamente o custo da informação.

Se o preço fosse perfeitamente revelador --- se agentes desinformados
pudessem inferir toda a informação privada observando o preço ---, não
haveria vantagem em pagar o custo \(c\). A fração de informados cairia a
zero. Mas com zero informados, o preço não conteria informação alguma,
tornando vantajoso pagar \(c\). A dinâmica oscilaria indefinidamente.

A solução requer que o preço seja apenas \emph{parcialmente} revelador.
Isto é obtido pela introdução de \emph{noise traders} --- agentes cujas
demandas são independentes de informação, motivadas por necessidades de
liquidez, rebalanceamento, ou irracionalidade. O ruído que estes agentes
introduzem impede que o preço revele perfeitamente a informação privada,
preservando incentivo para sua aquisição.

Em equilíbrio, a utilidade esperada de agentes informados e
desinformados iguala-se. A fração de informados \(\lambda^*\) satisfaz:

\[E[U(W | \text{informado})] - c = E[U(W | \text{desinformado})]\]

O grau de ineficiência --- a magnitude do alfa esperado para informados
--- é função crescente do custo da informação \(c\) e decrescente da
precisão com que preços revelam informação.

\hypertarget{extensuxf5es-contemporuxe2neas-e-eviduxeancia-empuxedrica}{%
\subsubsection{Extensões Contemporâneas e Evidência
Empírica}\label{extensuxf5es-contemporuxe2neas-e-eviduxeancia-empuxedrica}}

A literatura subsequente estendeu o paradigma Grossman-Stiglitz em
múltiplas direções. Verrecchia (1982) endogeniza a quantidade de
informação adquirida, mostrando que agentes investem em precisão até o
ponto onde benefício marginal iguala custo marginal. Hellwig; Veldkamp
(2009) estende a análise para mercados com múltiplos ativos e informação
heterogênea, demonstrando condições sob as quais a agregação de
informação é mais ou menos eficiente.

Stiglitz; Kosenko (2024) oferecem atualização abrangente do paradigma da
economia da informação. Argumentam que desenvolvimentos nas décadas
desde o trabalho original reforçam, mais que enfraquecem, a centralidade
das fricções informacionais. A revolução digital não eliminou
assimetrias de informação; em muitos casos, exacerbou-as, criando novas
formas de informação privada (dados alternativos, \emph{high-frequency
trading}) e novas fontes de ruído (desinformação, manipulação
algorítmica).

Pastushkov (2024) aplicam modelagem evolucionária ao problema.
Demonstram resultado contra-intuitivo: reduzir custos de informação não
necessariamente aumenta eficiência de preços. Quando informação se torna
muito barata, a vantagem competitiva de ser informado diminui,
potencialmente levando a equilíbrio onde a maioria permanece
desinformada --- \emph{free-riding} na informação produzida por poucos.
Apenas quando custos são moderados observa-se equilíbrio com fração
substancial de informados e preços relativamente eficientes.

A evidência empírica oferece suporte misto ao paradigma. Por um lado, a
existência de fundos de investimento ativamente gerenciados --- que
cobram taxas substanciais para produzir análise --- sugere que
investidores acreditam haver valor na informação. Por outro lado, a
maioria dos fundos ativos não supera benchmarks passivos após taxas
(Gruber, 1996), sugerindo que a competição por alfa é intensa e que a
maior parte do retorno à informação é capturada pelos próprios
analistas, não pelos investidores finais.

\hypertarget{o-motor-q-val-como-custo-da-informauxe7uxe3o}{%
\subsubsection{O Motor Q-VAL como ``Custo da
Informação''}\label{o-motor-q-val-como-custo-da-informauxe7uxe3o}}

O paradoxo de Grossman-Stiglitz fornece enquadramento teórico direto
para o presente trabalho. O motor Q-VAL --- sistema de scoring que
integra métricas de Valor, Qualidade e Risco --- representa investimento
em informação: coleta de dados fundamentalistas, processamento via
algoritmos de normalização e agregação, e síntese em sinal acionável.

A pergunta empírica pode ser reformulada em termos do teorema: o
``alfa'' gerado pelo motor Q-VAL --- medido via \(\Delta R^2\) em
relação ao modelo de mercado puro --- é suficiente para compensar o
``custo'' de sua produção? Se \(\Delta R^2\) for insignificante, o
mercado brasileiro aproxima-se da eficiência semi-forte; métricas
fundamentalistas públicas já estariam incorporadas aos preços. Se
\(\Delta R^2\) for positivo e significativo, existe espaço para que
análise fundamentalista adicione valor --- o grau de ineficiência é
suficiente para compensar custos informacionais.

A magnitude do \(\Delta R^2\) pode ser interpretada como proxy para o
``grau de ineficiência'' do mercado brasileiro com respeito a informação
fundamentalista. Valores elevados sugeririam que o mercado processa
lentamente --- ou com viés sistemático --- informação contábil pública.
Valores baixos sugeririam processamento eficiente. A análise por
subperíodos pode revelar variação temporal --- consistente com a AMH ---
onde ineficiências são maiores em certos regimes (crises, alta
volatilidade) e menores em outros.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{economia-da-complexidade-e-agregauxe7uxe3o-informacional}{%
\subsection{Economia da Complexidade e Agregação
Informacional}\label{economia-da-complexidade-e-agregauxe7uxe3o-informacional}}

\hypertarget{mercados-como-sistemas-adaptativos-complexos}{%
\subsubsection{Mercados como Sistemas Adaptativos
Complexos}\label{mercados-como-sistemas-adaptativos-complexos}}

A economia da complexidade oferece enquadramento radicalmente distinto
tanto da visão hayekiana quanto da EMH. Desenvolvida primordialmente no
Santa Fe Institute, com contribuições seminais de Arthur (2014) e
sintetizada em Arthur (2021), esta tradição rejeita a metáfora do
mercado como mecanismo de equilíbrio --- seja este estático (EMH) ou
dinâmico-convergente (Hayek) --- em favor da metáfora do mercado como
\emph{sistema adaptativo complexo}.

Sistemas adaptativos complexos exibem propriedades que os distinguem
tanto de sistemas mecânicos simples quanto de sistemas aleatórios puros:

\textbf{Emergência:} Padrões macroscópicos emergem de interações
microscópicas de modo não trivialmente dedutível das regras locais. O
preço de uma ação emerge de milhões de decisões individuais de compra e
venda, mas não pode ser previsto conhecendo-se apenas as regras que
governam cada decisão isolada.

\textbf{Auto-organização:} Estruturas ordenadas surgem espontaneamente
sem coordenação central. Mercados desenvolvem convenções, normas,
instituições --- desde horários de negociação até práticas contábeis ---
sem designer explícito.

\textbf{Não-linearidade:} Pequenas perturbações podem gerar efeitos
desproporcionais (sensibilidade às condições iniciais), enquanto grandes
perturbações podem ser absorvidas sem consequência. O colapso do Lehman
Brothers --- evento relativamente pequeno no contexto do sistema
financeiro global --- desencadeou crise sistêmica; outros eventos
comparáveis passaram sem repercussão.

\textbf{Adaptação:} Agentes modificam comportamento em resposta ao
ambiente, e o ambiente modifica-se em resposta ao comportamento
agregado. Estratégias que funcionam atraem imitadores; a imitação altera
o ambiente; estratégias que funcionavam deixam de funcionar.

\textbf{Path dependence:} A história importa. O estado atual do sistema
depende não apenas de parâmetros correntes, mas da trajetória pela qual
foi atingido. Mercados não ``esqueceram'' a crise de 2008;
participantes, reguladores e instituições foram permanentemente
alterados.

\hypertarget{agregauxe7uxe3o-de-informauxe7uxe3o-como-fenuxf4meno-emergente}{%
\subsubsection{Agregação de Informação como Fenômeno
Emergente}\label{agregauxe7uxe3o-de-informauxe7uxe3o-como-fenuxf4meno-emergente}}

A perspectiva da complexidade reconceptualiza a agregação de informação.
Na visão hayekiana clássica, preços \emph{condensam} informação
dispersa, servindo como estatísticas suficientes que permitem
coordenação. Na EMH, preços \emph{refletem} informação, igualando-se ao
valor esperado condicional a toda informação disponível. Na economia da
complexidade, preços \emph{emergem} de interações que podem tanto
agregar quanto distorcer informação.

Arthur (1994) desenvolvem modelo seminal --- o Bar Problem ---
demonstrando como agentes com racionalidade limitada, usando heurísticas
heterogêneas, podem atingir coordenação eficiente em média, mas com
flutuações persistentes que não convergem a equilíbrio. Aplicado a
mercados, o modelo sugere que preços oscilam perpetuamente em torno de
``valor fundamental'' sem jamais estabilizar --- não por choques
exógenos, mas por dinâmica endógena do sistema.

O modelo de mercado artificial do Santa Fe Institute (LeBaron, 2006)
simula mercados com agentes heterogêneos que usam regras de decisão
evolucionárias. Os resultados reproduzem ``fatos estilizados''
observados em mercados reais --- caudas gordas nas distribuições de
retornos, volatilidade clustering, correlação serial de volatilidade ---
que modelos de equilíbrio não capturam. Crucialmente, a eficiência
informacional do mercado simulado varia: em certos parâmetros, preços
rastreiam fundamentos eficientemente; em outros, bolhas e crashes
emergem endogenamente.

\hypertarget{herding-cascatas-e-amplificauxe7uxe3o-de-ruuxeddo}{%
\subsubsection{Herding, Cascatas e Amplificação de
Ruído}\label{herding-cascatas-e-amplificauxe7uxe3o-de-ruuxeddo}}

A economia da complexidade enfatiza mecanismos pelos quais informação
pode ser sistematicamente distorcida --- não apenas agregada --- pelo
mecanismo de mercado.

\textbf{Herding (comportamento de manada):} Agentes podem racionalmente
ignorar informação privada para seguir o comportamento observado de
outros. Se muitos agentes precedentes compraram um ativo, o agente
seguinte pode inferir que eles possuíam informação favorável, e comprar
mesmo que sua própria informação seja desfavorável. O resultado é
cascata informacional onde informação privada é perdida e o grupo
converge para decisão potencialmente errada (Bikhchandani; Hirshleifer;
Welch, 1992).

\textbf{Feedback positivo:} Se o aumento de preço de um ativo atrai
compradores adicionais --- seja porque interpretam o aumento como sinal
informativo, seja porque regras de momentum assim ditam ---, o próprio
movimento de preço gera demanda adicional, desacoplando preços de
fundamentos. Bolhas especulativas são manifestação extrema deste
mecanismo.

\textbf{Reflexividade:} Conceito desenvolvido por Soros (1987), a
reflexividade descreve o fenômeno pelo qual expectativas afetam a
realidade que pretendem prever. Se analistas acreditam que uma empresa é
sólida, concedem crédito a termos favoráveis, atraem talentos, geram
cobertura positiva --- tornando a empresa efetivamente mais sólida.
Preços não apenas refletem fundamentos; influenciam-nos.

\textbf{Contágio informacional:} Informação --- e desinformação ---
propaga-se através de redes sociais de modo que pode amplificar certos
sinais e suprimir outros. Bollen; Mao; Zeng (2011) documentam correlação
entre sentimento em redes sociais e retornos subsequentes, sugerindo que
``informação'' incorporada a preços pode incluir ruído social
sistematicamente enviesado.

\hypertarget{implicauxe7uxf5es-para-o-motor-q-val}{%
\subsubsection{Implicações para o Motor
Q-VAL}\label{implicauxe7uxf5es-para-o-motor-q-val}}

A perspectiva da complexidade sugere cautela interpretativa quanto aos
resultados do motor Q-VAL.

\textbf{Regime-dependência:} O poder preditivo de métricas
fundamentalistas pode variar substancialmente entre regimes de mercado.
Em períodos de baixa volatilidade e liquidez abundante, quando capital
busca ativamente oportunidades, ineficiências tendem a ser rapidamente
arbitradas. Em períodos de crise, quando aversão ao risco domina e
capital foge para ativos seguros, ineficiências podem ampliar-se ---
ativos subavaliados podem tornar-se mais subavaliados antes de reverter.

\textbf{Reflexividade das métricas:} Se o score Q-VAL --- ou métricas
similares --- for amplamente adotado, sua própria utilização afetará os
preços que pretende prever. Empresas que recebem scores elevados atraem
fluxo de investimento, elevando preços até que a ``oportunidade''
desapareça. Há risco de \emph{self-defeating prophecy} --- métricas que
funcionam deixam de funcionar justamente porque funcionam.

\textbf{Ruído vs.~sinal:} A economia da complexidade alerta que nem toda
informação incorporada a preços é ``informação'' no sentido de
conhecimento verdadeiro sobre fundamentos. Parte é ruído --- flutuações
aleatórias, comportamento de manada, cascatas informacionais. O aumento
de \(R^2\) observado pode refletir captura de padrões de ruído
correlacionado, não genuína informação sobre valor fundamental.

\textbf{Não-linearidade:} Modelos lineares --- como as regressões
propostas na metodologia --- podem capturar apenas parcela das relações.
Interações não-lineares entre métricas, efeitos de limiar
(\emph{threshold effects}), e dinâmicas de feedback podem requerer
especificações mais flexíveis. A literatura recente em machine learning
para precificação de ativos (Gu; Kelly; Xiu, 2020) documenta ganhos
substanciais com métodos não-lineares, sugerindo que especificações
lineares subestimam o conteúdo informacional de métricas
fundamentalistas.

\hypertarget{suxedntese-quatro-visuxf5es-sobre-informauxe7uxe3o-e-preuxe7os}{%
\subsubsection{Síntese: Quatro Visões sobre Informação e
Preços}\label{suxedntese-quatro-visuxf5es-sobre-informauxe7uxe3o-e-preuxe7os}}

O arcabouço teórico desenvolvido nesta seção pode ser sintetizado
contrastando quatro visões sobre a relação entre informação e preços:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1471}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2647}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.5882}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Tradição
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Metáfora Central
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implicação para Análise Fundamentalista
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Hayek} & Mercado como telecomunicação & Preços condensam
conhecimento tácito; análise pode antecipar processamento \\
\textbf{Fama (EMH)} & Mercado como espelho & Preços refletem informação;
análise de dados públicos é inútil \\
\textbf{Grossman-Stiglitz} & Mercado como incentivo & Ineficiência
necessária; análise é compensada por alfa \\
\textbf{Complexidade} & Mercado como ecossistema & Eficiência variável;
análise funciona em certos nichos/regimes \\
\end{longtable}

Estas visões não são mutuamente exclusivas. A EMH pode aproximar-se da
verdade para ativos líquidos em mercados desenvolvidos, enquanto a
economia da complexidade melhor descreve mercados emergentes ou ativos
ilíquidos. O paradoxo de Grossman-Stiglitz opera em todos os contextos,
estabelecendo limite inferior para ineficiência. A intuição hayekiana
permanece válida como descrição do \emph{processo} --- ainda que o
\emph{resultado} possa aproximar-se de eficiência em alguns casos e
afastar-se em outros.

Para o caso Petrobras, múltiplas considerações são relevantes. Por um
lado, trata-se de ativo extremamente líquido, com alta cobertura de
analistas, sugerindo eficiência elevada. Por outro lado, a empresa está
inserida em contexto de mercado emergente, sujeita a interferência
estatal, exposta a incerteza estrutural (Margem Equatorial), e
caracterizada por complexidade contábil do setor de óleo e gás ---
fatores que podem gerar fricções informacionais persistentes.

A análise empírica subsequente buscará distinguir entre estas
possibilidades, examinando se o motor Q-VAL adiciona poder explicativo
ao modelo de mercado puro, e se este poder explicativo varia ao longo do
tempo de modo consistente com a hipótese dos mercados adaptativos.

\hypertarget{contextualizauxe7uxe3o-petrobras-e-a-margem-equatorial}{%
\section{Contextualização: Petrobras e a Margem
Equatorial}\label{contextualizauxe7uxe3o-petrobras-e-a-margem-equatorial}}

\hypertarget{trajetuxf3ria-histuxf3rica-e-institucional}{%
\subsection{Trajetória Histórica e
Institucional}\label{trajetuxf3ria-histuxf3rica-e-institucional}}

A Petróleo Brasileiro S.A. --- Petrobras --- foi constituída em 1953
como instrumento da política desenvolvimentista que marcou o período
Vargas. A criação da empresa estatal respondeu a demandas nacionalistas
por controle dos recursos petrolíferos, sintetizadas na campanha ``O
Petróleo é Nosso'' que mobilizou segmentos diversos da sociedade
brasileira. O monopólio estatal sobre exploração, produção e refino,
estabelecido pela Lei 2.004/1953, configurou modelo que prevaleceria por
mais de quatro décadas.

A quebra parcial do monopólio em 1997, durante o governo Fernando
Henrique Cardoso, inaugurou nova fase. A Emenda Constitucional nº 9/1995
e a Lei do Petróleo (9.478/1997) permitiram a entrada de empresas
privadas no setor, embora a Petrobras mantivesse posição dominante. A
abertura de capital, com listagem simultânea na B3 e NYSE, introduziu
pressões de governança corporativa e transparência típicas de companhias
abertas. A empresa passou a operar sob dupla lógica: instrumento de
política energética nacional e maximizadora de valor para acionistas.

A descoberta do pré-sal em 2006 representou inflexão histórica. As
reservas identificadas na camada de rochas carbonáticas sob espessa
camada de sal, em águas ultraprofundas da Bacia de Santos, posicionaram
o Brasil entre as principais fronteiras petrolíferas globais. O
desenvolvimento do pré-sal exigiu investimentos massivos em tecnologia
de perfuração e produção em condições extremas --- capacidade que a
Petrobras desenvolveu tornando-se referência mundial em águas profundas.

O período subsequente foi marcado por escândalo de corrupção de
proporções inéditas. A Operação Lava Jato, deflagrada em 2014, revelou
esquema de pagamentos ilícitos envolvendo contratos da Petrobras,
partidos políticos e empreiteiras. As consequências foram severas:
baixas contábeis bilionárias, rebaixamento de rating de crédito, queda
abrupta do valor de mercado, e crise de governança que culminou em
renovação completa da alta administração. A recuperação, iniciada a
partir de 2016, envolveu desinvestimentos, redução de alavancagem e foco
em ativos de maior rentabilidade --- notadamente o pré-sal.

\hypertarget{o-cenuxe1rio-atual-margem-equatorial-e-transiuxe7uxe3o-energuxe9tica}{%
\subsection{O Cenário Atual: Margem Equatorial e Transição
Energética}\label{o-cenuxe1rio-atual-margem-equatorial-e-transiuxe7uxe3o-energuxe9tica}}

A Margem Equatorial brasileira compreende as bacias sedimentares da
costa norte do país, estendendo-se do Amapá ao Rio Grande do Norte.
Trata-se de fronteira exploratória praticamente inexplorada, com
potencial estimado entre 10 e 30 bilhões de barris de petróleo ---
volume que poderia duplicar as reservas provadas brasileiras. A região
apresenta características geológicas análogas a províncias produtoras da
costa oeste africana, onde descobertas significativas foram realizadas
nas últimas décadas.

A autorização para exploração da Margem Equatorial, concedida pelo IBAMA
em 2024-2025, reacendeu debates sobre a estratégia de longo prazo da
Petrobras. De um lado, a exploração representa oportunidade de expansão
de reservas em momento em que campos maduros declinam e o pré-sal,
embora produtivo, apresenta horizonte finito. De outro, implica
investimentos vultosos --- estimados entre US\$ 50 e 100 bilhões --- com
retorno incerto e prazo de maturação superior a uma década.

O contexto de transição energética adiciona camada de complexidade à
decisão. O Acordo de Paris e os compromissos subsequentes de
neutralidade de carbono pressionam empresas petrolíferas a reorientar
portfólios para fontes renováveis. Investidores institucionais,
especialmente fundos de pensão europeus e gestores com mandatos ESG,
questionam a racionalidade de investimentos em novas fronteiras fósseis.
A Petrobras enfrenta, nesse cenário, tensão entre maximização de valor
de curto prazo via exploração de reservas e posicionamento estratégico
para economia descarbonizada.

Os riscos regulatórios e ambientais da Margem Equatorial são
substanciais. A região abriga ecossistemas sensíveis, incluindo
manguezais, recifes de coral e áreas de reprodução de espécies marinhas.
O licenciamento ambiental tem sido objeto de contestação judicial e
mobilização de organizações ambientalistas. Vazamentos ou acidentes em
área de difícil acesso teriam consequências potencialmente graves, com
repercussões sobre a reputação da empresa e sua licença social para
operar.

\hypertarget{implicauxe7uxf5es-para-valuation}{%
\subsection{Implicações para
Valuation}\label{implicauxe7uxf5es-para-valuation}}

A avaliação da PETR4 no contexto descrito envolve ponderação de cenários
com probabilidades e payoffs distintos. No cenário otimista, a
exploração da Margem Equatorial confirma potencial geológico, custos de
desenvolvimento permanecem controlados, e preços de petróleo
sustentam-se em patamares remuneradores. Os fluxos de caixa incrementais
justificam o investimento e o valor da empresa aumenta
significativamente. No cenário pessimista, reservas mostram-se menores
que o esperado, custos escalam além das projeções, preços de petróleo
colapsam com aceleração da transição energética, e pressões ESG
restringem acesso a capital. Os investimentos tornam-se \emph{stranded
assets} e o valor da empresa deteriora-se.

O mercado, ao precificar a PETR4, pondera implicitamente esses cenários.
A pergunta relevante para o investidor é se essa ponderação está correta
--- se o preço corrente reflete adequadamente o valor esperado da
empresa considerando probabilidades e magnitudes dos diferentes
cenários. A análise de \emph{mispricing} via comparação entre custo de
capital implícito e custo de capital teórico (CAPM) oferece uma
abordagem para essa questão.

\hypertarget{metodologia}{%
\section{Metodologia}\label{metodologia}}

A metodologia deste trabalho articula três componentes integrados: (i) a
construção do motor Q-VAL como sistema de agregação de informação
fundamentalista, (ii) a especificação de modelos econométricos
comparativos que permitem isolar a contribuição informacional de cada
componente, e (iii) a definição de métricas de avaliação que
operacionalizam conceitos teóricos --- eficiência informacional,
contribuição marginal, parcimônia --- em quantidades mensuráveis. A
integração destes componentes permite responder à pergunta central:
métricas fundamentalistas adicionam informação ao processo de
precificação, ou essa informação já está incorporada aos preços?

A estratégia empírica segue lógica de \emph{nested models} (modelos
aninhados), partindo de especificação mínima --- o CAPM unifatorial ---
e progressivamente incorporando vetores de informação fundamentalista. A
comparação entre modelos sucessivos, via métricas como \(\Delta R^2\) e
critérios de informação, permite atribuir a cada componente sua
contribuição marginal explicativa. Esta abordagem dialoga diretamente
com o paradoxo de Grossman-Stiglitz: se métricas públicas já estão
precificadas, sua adição não deveria melhorar o poder explicativo; se
existe ineficiência compensadora, a melhoria será estatisticamente
detectável.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{o-motor-q-val-como-vetor-de-informauxe7uxe3o-fundamentalista}{%
\subsection{O Motor Q-VAL como Vetor de Informação
Fundamentalista}\label{o-motor-q-val-como-vetor-de-informauxe7uxe3o-fundamentalista}}

\hypertarget{arquitetura-conceitual}{%
\subsubsection{Arquitetura Conceitual}\label{arquitetura-conceitual}}

O motor Q-VAL (\emph{Quantitative Value}) constitui sistema de
\emph{scoring} fundamentalista que integra múltiplas dimensões de
avaliação em índice sintético. A denominação remete à tradição de
\emph{Quantitative Value Investing} sistematizada por Gray; Carlisle
(2012), que propõe automatização de princípios de análise
fundamentalista clássica --- originários de Graham; Dodd (1934) --- via
algoritmos computacionais que eliminam vieses comportamentais e garantem
consistência metodológica.

A arquitetura do motor organiza-se em três dimensões canônicas:

\textbf{Dimensão de Valor:} Captura a relação entre preço de mercado e
fundamentos contábeis. Métricas de valor respondem à pergunta:
\emph{quanto o mercado está pagando por unidade de fundamento econômico?
} Valores baixos (P/L reduzido, EV/EBITDA comprimido) sugerem
subavaliação --- o mercado atribui ao ativo preço inferior ao que seus
fundamentos justificariam. A literatura documenta \emph{value premium}
persistente: ativos ``baratos'' tendem, em média, a superar ativos
``caros'' em horizontes de médio prazo (Asness; Moskowitz; Pedersen,
2013; Fama; French, 1993).

\textbf{Dimensão de Qualidade:} Avalia a eficiência operacional e
sustentabilidade dos resultados. Métricas de qualidade respondem à
pergunta: \emph{quão eficientemente a empresa converte capital em
retorno? } Valores elevados (ROE alto, margens robustas, crescimento
consistente) indicam vantagens competitivas que tendem a persistir.
Novy-Marx (2013) documenta que lucratividade possui poder preditivo
comparável ao de métricas de valor, enquanto Asness; Frazzini; Pedersen
(2019b) formalizam ``qualidade'' como fator distinto com prêmio próprio.

\textbf{Dimensão de Risco:} Incorpora indicadores de alavancagem,
liquidez e volatilidade. Métricas de risco respondem à pergunta:
\emph{qual a probabilidade de deterioração dos fundamentos ou de eventos
adversos?} A inclusão desta dimensão reconhece que ativos ``baratos e de
qualidade'' podem sê-lo por razões legítimas --- risco elevado que
justifica desconto. A dimensão de risco serve como \emph{hedge} contra
\emph{value traps}: ativos superficialmente atrativos que ocultam
fragilidades estruturais.

\hypertarget{muxe9tricas-selecionadas}{%
\subsubsection{Métricas Selecionadas}\label{muxe9tricas-selecionadas}}

A seleção de métricas segue critérios de relevância teórica,
disponibilidade de dados, e robustez empírica documentada na literatura.
Para cada dimensão, escolheu-se conjunto parcimonioso de indicadores que
capturam facetas complementares:

\hypertarget{dimensuxe3o-de-valor}{%
\paragraph{Dimensão de Valor}\label{dimensuxe3o-de-valor}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2571}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3143}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Métrica
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definição
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretação
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Earnings Yield (EY)} &
\(\frac{\text{LPA}}{\text{Preço}} = \frac{1}{\text{P/L}}\) & Retorno
implícito do lucro; inverso do P/L \\
\textbf{EV/EBITDA} & \(\frac{\text{Enterprise Value}}{\text{EBITDA}}\) &
Múltiplo de valor da firma sobre geração de caixa operacional \\
\textbf{P/VP} &
\(\frac{\text{Preço}}{\text{Valor Patrimonial por Ação}}\) & Relação
entre valor de mercado e valor contábil \\
\textbf{Dividend Yield (DY)} &
\(\frac{\text{Dividendos por Ação}}{\text{Preço}}\) & Retorno em
dividendos \\
\end{longtable}

O \emph{Earnings Yield} é preferido ao P/L por conveniência matemática:
valores mais altos indicam maior atratividade (inversamente ao P/L),
facilitando agregação com outras métricas onde ``maior é melhor''. O
EV/EBITDA captura valor da firma inteira --- incluindo dívida --- sobre
geração de caixa operacional, sendo particularmente relevante para
empresas intensivas em capital como a Petrobras.

\hypertarget{dimensuxe3o-de-qualidade}{%
\paragraph{Dimensão de Qualidade}\label{dimensuxe3o-de-qualidade}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2571}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3143}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Métrica
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definição
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretação
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{ROIC} & \(\frac{\text{NOPAT}}{\text{Capital Investido}}\) &
Retorno sobre capital investido \\
\textbf{ROE} &
\(\frac{\text{Lucro Líquido}}{\text{Patrimônio Líquido}}\) & Retorno
sobre patrimônio \\
\textbf{Margem EBITDA} &
\(\frac{\text{EBITDA}}{\text{Receita Líquida}}\) & Eficiência
operacional \\
\textbf{EVS} & \(\text{ROIC} - \text{WACC}\) & Economic Value Spread;
criação de valor \\
\end{longtable}

O \emph{Economic Value Spread} (EVS) merece destaque. Conforme
desenvolvido na seção de fundamentos teóricos, o EVS captura criação de
valor em termos relativos ao custo de capital. Valor positivo indica que
a empresa gera retorno superior ao custo de oportunidade do capital
empregado --- condição necessária para criação sustentável de valor ao
acionista. Para empresas do setor de óleo e gás, onde ciclos de
investimento são longos e intensivos em capital, o EVS oferece
perspectiva mais informativa que métricas de rentabilidade brutas.

\hypertarget{dimensuxe3o-de-risco}{%
\paragraph{Dimensão de Risco}\label{dimensuxe3o-de-risco}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2571}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3143}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4286}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Métrica
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Definição
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretação
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Beta} & \(\frac{\text{Cov}(R_i, R_m)}{\text{Var}(R_m)}\) &
Sensibilidade ao mercado \\
\textbf{Volatilidade} & \(\sigma_i = \sqrt{\text{Var}(R_i)}\) &
Desvio-padrão dos retornos \\
\textbf{Dívida/PL} &
\(\frac{\text{Dívida Total}}{\text{Patrimônio Líquido}}\) & Alavancagem
financeira \\
\textbf{Liquidez Corrente} &
\(\frac{\text{Ativo Circulante}}{\text{Passivo Circulante}}\) &
Capacidade de pagamento de curto prazo \\
\end{longtable}

O beta, estimado via regressão conforme detalhado adiante, captura risco
sistemático --- a parcela do risco que não pode ser eliminada por
diversificação. A volatilidade captura risco total. A razão Dívida/PL
indica exposição a risco financeiro --- empresas alavancadas são mais
sensíveis a choques de receita e taxa de juros. A liquidez corrente
sinaliza risco de curto prazo --- capacidade de honrar obrigações
imediatas.

\hypertarget{procedimento-de-normalizauxe7uxe3o}{%
\subsubsection{Procedimento de
Normalização}\label{procedimento-de-normalizauxe7uxe3o}}

Métricas heterogêneas --- expressas em unidades distintas (percentuais,
múltiplos, razões) e com escalas variadas --- requerem normalização para
agregação. O procedimento adotado é a \emph{padronização Z-Score}
relativa a benchmarks setoriais:

\[Z_i = \frac{X_i - \mu_{\text{setor}}}{\sigma_{\text{setor}}}\]

onde \(X_i\) é o valor da métrica para o ativo \(i\),
\(\mu_{\text{setor}}\) é a média setorial, e \(\sigma_{\text{setor}}\) é
o desvio-padrão setorial. O Z-Score indica quantos desvios-padrão o
ativo se afasta da média do setor: \(Z = +1\) indica desempenho um
desvio-padrão acima da média; \(Z = -1\), um desvio abaixo.

Para métricas onde valores \emph{menores} são preferíveis (P/VP,
EV/EBITDA, Dívida/PL, Volatilidade, Beta), o Z-Score é invertido:

\[Z_i^{\text{inv}} = -Z_i = \frac{\mu_{\text{setor}} - X_i}{\sigma_{\text{setor}}}\]

Esta inversão garante que, para todas as métricas normalizadas, valores
mais altos indicam maior atratividade.

Os benchmarks setoriais são obtidos de empresas comparáveis do setor de
óleo e gás integrado, utilizando dados de empresas listadas na B3 e,
quando necessário para robustez estatística, médias de empresas
latino-americanas do setor obtidas via bases de dados internacionais.

\hypertarget{agregauxe7uxe3o-em-score-composto}{%
\subsubsection{Agregação em Score
Composto}\label{agregauxe7uxe3o-em-score-composto}}

Os Z-Scores normalizados são agregados em score composto via média
ponderada:

\[\text{Score}_{\text{Dimensão}} = \sum_{j=1}^{n} w_j \cdot Z_j\]

onde \(w_j\) são pesos atribuídos a cada métrica dentro da dimensão, com
\(\sum w_j = 1\). Na implementação base, pesos iguais são atribuídos a
cada métrica dentro de cada dimensão (\(w_j = 1/n\)).

O score final Q-VAL agrega as três dimensões:

\[\text{Q-VAL} = w_V \cdot \text{Score}_{\text{Valor}} + w_Q \cdot \text{Score}_{\text{Qualidade}} + w_R \cdot \text{Score}_{\text{Risco}}\]

Na configuração base, pesos iguais são atribuídos às dimensões
(\(w_V = w_Q = w_R = 1/3\)). A análise de sensibilidade examina
configurações alternativas.

Para facilitar interpretação, o score é transformado em escala 0-100:

\[\text{Q-VAL}_{[0,100]} = 50 + 10 \cdot \text{Q-VAL}_{\text{bruto}}\]

Scores acima de 60 indicam recomendação de \emph{Compra}; entre 40 e 60,
\emph{Neutro}; abaixo de 40, \emph{Venda}. Estes limiares correspondem
aproximadamente a \(\pm 1\) desvio-padrão em torno da média.

\hypertarget{suxe9rie-temporal-de-scores}{%
\subsubsection{Série Temporal de
Scores}\label{suxe9rie-temporal-de-scores}}

Para a análise de contribuição informacional, é necessário construir
série temporal de scores. A cada período \(t\), o score Q-VAL é
calculado utilizando apenas informação disponível até \(t\) --- critério
essencial para evitar \emph{look-ahead bias}. Formalmente:

\[\text{Q-VAL}_t = f(\mathcal{I}_t)\]

onde \(\mathcal{I}_t\) denota o conjunto de informação disponível no
período \(t\). Na prática, dados contábeis são defasados: demonstrações
financeiras do trimestre \(q\) tornam-se públicas apenas semanas após o
encerramento do trimestre. O procedimento utiliza dados do trimestre
\(q-1\) para calcular scores no trimestre \(q\), garantindo que toda
informação utilizada era publicamente disponível no momento da decisão.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{modelos-economuxe9tricos-comparativos}{%
\subsection{Modelos Econométricos
Comparativos}\label{modelos-economuxe9tricos-comparativos}}

\hypertarget{estratuxe9gia-de-modelos-aninhados}{%
\subsubsection{Estratégia de Modelos
Aninhados}\label{estratuxe9gia-de-modelos-aninhados}}

A estratégia empírica baseia-se em comparação de modelos aninhados
(\emph{nested models}), partindo de especificação mínima e
progressivamente incorporando regressores. Esta abordagem permite
decompor o poder explicativo total em contribuições atribuíveis a cada
componente, testando se a adição de variáveis fundamentalistas melhora
significativamente a explicação dos retornos.

Sejam \(\mathcal{M}_0, \mathcal{M}_1, \ldots, \mathcal{M}_K\) modelos
aninhados, onde
\(\mathcal{M}_0 \subset \mathcal{M}_1 \subset \ldots \subset \mathcal{M}_K\)
(cada modelo contém os regressores do anterior mais regressores
adicionais). A comparação entre \(\mathcal{M}_k\) e
\(\mathcal{M}_{k-1}\) permite testar se os regressores adicionais em
\(\mathcal{M}_k\) contribuem significativamente para explicar a variável
dependente.

\hypertarget{modelo-0-capm-baseline}{%
\subsubsection{Modelo 0: CAPM (Baseline)}\label{modelo-0-capm-baseline}}

O modelo base é o Capital Asset Pricing Model unifatorial, que
representa a informação contida exclusivamente nos preços de mercado:

\[R_{i,t} - R_{f,t} = \alpha_i + \beta_i (R_{m,t} - R_{f,t}) + \varepsilon_{i,t}\]

onde: - \(R_{i,t}\): retorno do ativo \(i\) no período \(t\) -
\(R_{f,t}\): taxa livre de risco no período \(t\) - \(R_{m,t}\): retorno
do portfólio de mercado no período \(t\) - \(\alpha_i\): intercepto
(alfa de Jensen) - \(\beta_i\): coeficiente de sensibilidade ao mercado
(beta) - \(\varepsilon_{i,t}\): termo de erro, com
\(E[\varepsilon_{i,t}] = 0\) e
\(\text{Var}(\varepsilon_{i,t}) = \sigma^2_\varepsilon\)

O CAPM postula que \(\alpha_i = 0\) em equilíbrio: todo o retorno
esperado em excesso é explicado pela exposição ao risco de mercado. Alfa
positivo indica retorno anormal --- desempenho superior ao previsto pelo
modelo dado o nível de risco.

\textbf{Operacionalização:} - \(R_{i,t}\): retorno logarítmico diário de
PETR4, calculado como \(\ln(P_t / P_{t-1})\) - \(R_{f,t}\): taxa CDI
diária, obtida via série histórica do Banco Central - \(R_{m,t}\):
retorno logarítmico diário do Ibovespa

A estimação utiliza Mínimos Quadrados Ordinários (OLS). O beta estimado
\(\hat{\beta}_i\) é dado por:

\[\hat{\beta}_i = \frac{\text{Cov}(R_i - R_f, R_m - R_f)}{\text{Var}(R_m - R_f)}\]

O \(R^2\) do Modelo 0 indica a fração da variância dos retornos de PETR4
explicada pelo movimento do mercado. Este valor serve como
\emph{baseline} para comparação com modelos subsequentes.

\hypertarget{modelo-1-capm-fator-de-valor}{%
\subsubsection{Modelo 1: CAPM + Fator de
Valor}\label{modelo-1-capm-fator-de-valor}}

O primeiro modelo estendido adiciona um fator de valor --- métrica
fundamentalista única --- ao CAPM:

\[R_{i,t} - R_{f,t} = \alpha_i + \beta_i (R_{m,t} - R_{f,t}) + \gamma_1 \cdot \text{Value}_{t-1} + \varepsilon_{i,t}\]

onde \(\text{Value}_{t-1}\) é o Z-Score da dimensão de Valor no período
anterior. O subscrito \(t-1\) é crucial: utiliza-se informação
fundamentalista \emph{defasada} para prever retorno \emph{corrente},
evitando simultaneidade e garantindo que o modelo é operacionalmente
implementável (a informação estava disponível antes do retorno ocorrer).

O coeficiente \(\gamma_1\) captura a relação entre posição
fundamentalista de valor e retorno subsequente. Valor positivo e
significativo indicaria que ativos ``baratos'' (alto Z-Score de Valor)
tendem a gerar retornos superiores --- evidência de \emph{value premium}
não capturada pelo beta de mercado.

\hypertarget{modelo-2-capm-truxeas-dimensuxf5es-fundamentalistas}{%
\subsubsection{Modelo 2: CAPM + Três Dimensões
Fundamentalistas}\label{modelo-2-capm-truxeas-dimensuxf5es-fundamentalistas}}

O segundo modelo estendido incorpora as três dimensões do Q-VAL
separadamente:

\[R_{i,t} - R_{f,t} = \alpha_i + \beta_i (R_{m,t} - R_{f,t}) + \gamma_1 \cdot \text{Value}_{t-1} + \gamma_2 \cdot \text{Quality}_{t-1} + \gamma_3 \cdot \text{Risk}_{t-1} + \varepsilon_{i,t}\]

Esta especificação permite identificar a contribuição marginal de cada
dimensão. Os coeficientes \(\gamma_1, \gamma_2, \gamma_3\) indicam,
respectivamente: - \(\gamma_1 > 0\): ativos baratos tendem a superar
após controlar por qualidade e risco - \(\gamma_2 > 0\): ativos de
qualidade superior tendem a superar após controlar por valor e risco -
\(\gamma_3 > 0\): ativos de menor risco (Z-Score invertido, logo maior Z
indica menor risco) tendem a superar após controlar por valor e
qualidade

A significância individual de cada coeficiente informa sobre a
contribuição de cada dimensão. A comparação do \(R^2\) com o Modelo 1
informa sobre a contribuição conjunta de Qualidade e Risco além de
Valor.

\hypertarget{modelo-3-capm-score-q-val-sintuxe9tico}{%
\subsubsection{Modelo 3: CAPM + Score Q-VAL
Sintético}\label{modelo-3-capm-score-q-val-sintuxe9tico}}

O terceiro modelo utiliza o score composto Q-VAL como regressor único:

\[R_{i,t} - R_{f,t} = \alpha_i + \beta_i (R_{m,t} - R_{f,t}) + \lambda \cdot \text{Q-VAL}_{t-1} + \varepsilon_{i,t}\]

O coeficiente \(\lambda\) captura a relação entre o score agregado e
retornos subsequentes. Esta especificação testa se a síntese das três
dimensões em índice único preserva (ou potencialmente amplifica) o poder
informacional.

A comparação entre Modelos 2 e 3 é informativa. Se
\(R^2_{\text{Modelo 3}} \approx R^2_{\text{Modelo 2}}\), a agregação não
perde informação relevante. Se
\(R^2_{\text{Modelo 3}} < R^2_{\text{Modelo 2}}\), a agregação suprime
heterogeneidade informativa entre dimensões. Se
\(R^2_{\text{Modelo 3}} > R^2_{\text{Modelo 2}}\), a agregação reduz
ruído e amplifica sinal --- resultado contra-intuitivo que indicaria
overfitting nas dimensões separadas.

\hypertarget{especificauxe7uxe3o-com-retornos-futuros}{%
\subsubsection{Especificação com Retornos
Futuros}\label{especificauxe7uxe3o-com-retornos-futuros}}

Para testar capacidade preditiva --- não apenas contemporânea ---,
especificação alternativa utiliza retorno futuro como variável
dependente:

\[R_{i,t+h} - R_{f,t+h} = \alpha_i + \beta_i (R_{m,t+h} - R_{f,t+h}) + \lambda \cdot \text{Q-VAL}_{t} + \varepsilon_{i,t+h}\]

onde \(h\) é o horizonte de previsão (1 dia, 5 dias, 21 dias, 63 dias,
252 dias). Esta especificação testa se informação fundamentalista
antecipa retornos futuros --- condição necessária para que a análise
fundamentalista seja operacionalmente útil para decisões de
investimento.

\hypertarget{considerauxe7uxf5es-economuxe9tricas}{%
\subsubsection{Considerações
Econométricas}\label{considerauxe7uxf5es-economuxe9tricas}}

\textbf{Heterocedasticidade:} Séries financeiras tipicamente exibem
volatilidade variável no tempo (\emph{volatility clustering}).
Erros-padrão robustos à heterocedasticidade (Huber-White) são utilizados
para inferência.

\textbf{Autocorrelação:} Retornos diários podem exibir autocorrelação de
curto prazo. Testes de Durbin-Watson e Breusch-Godfrey verificam a
presença de autocorrelação residual. Quando detectada, erros-padrão
Newey-West são utilizados.

\textbf{Multicolinearidade:} As três dimensões fundamentalistas podem
ser correlacionadas. A matriz de correlação entre regressores é
examinada, e o \emph{Variance Inflation Factor} (VIF) é calculado. VIF
superior a 5 indicaria multicolinearidade problemática, requerendo
ortogonalização ou exclusão de variáveis.

\textbf{Estacionariedade:} Séries de retornos são tipicamente
estacionárias (retornos são diferenças de log-preços). Testes ADF
(\emph{Augmented Dickey-Fuller}) confirmam estacionariedade das séries
utilizadas.

\textbf{Outliers:} Eventos extremos (crises, circuit breakers) podem
distorcer estimativas. Análise de resíduos identifica observações
influentes; estimação robusta (regressão quantílica, \emph{winsorização}
de extremos) verifica sensibilidade dos resultados.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{muxe9tricas-de-avaliauxe7uxe3o-informacional}{%
\subsection{Métricas de Avaliação
Informacional}\label{muxe9tricas-de-avaliauxe7uxe3o-informacional}}

\hypertarget{coeficiente-de-determinauxe7uxe3o-e-sua-variauxe7uxe3o}{%
\subsubsection{Coeficiente de Determinação e Sua
Variação}\label{coeficiente-de-determinauxe7uxe3o-e-sua-variauxe7uxe3o}}

O coeficiente de determinação \(R^2\) mede a fração da variância da
variável dependente explicada pelo modelo:

\[R^2 = 1 - \frac{\text{SQR}}{\text{SQT}} = 1 - \frac{\sum_{t=1}^{T}(y_t - \hat{y}_t)^2}{\sum_{t=1}^{T}(y_t - \bar{y})^2}\]

onde SQR é a soma dos quadrados dos resíduos e SQT é a soma dos
quadrados totais.

O \(R^2\) varia entre 0 (modelo não explica nada além da média) e 1
(modelo explica perfeitamente). Para modelos de precificação de ativos,
valores típicos situam-se entre 0,20 e 0,50 para dados de alta
frequência (diários) e podem ser menores para dados de baixa frequência
ou para ativos individuais.

\textbf{Variação do \(R^2\) (\(\Delta R^2\)):}

A métrica central deste trabalho é a variação do coeficiente de
determinação entre modelos aninhados:

\[\Delta R^2_{k} = R^2_{\mathcal{M}_k} - R^2_{\mathcal{M}_{k-1}}\]

Esta quantidade mede a contribuição marginal dos regressores adicionais
no modelo \(k\) à explicação da variância.

\textbf{Interpretação à luz da teoria:}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2444}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4222}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Resultado
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Interpretação
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Implicação Teórica
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\Delta R^2 \approx 0\) & Métricas fundamentalistas não adicionam poder
explicativo & Mercado eficiente; informação já precificada (Fama) \\
\(\Delta R^2 > 0\), pequeno & Contribuição marginal modesta &
Ineficiência limitada; compensação por custo informacional
(Grossman-Stiglitz) \\
\(\Delta R^2 > 0\), substancial & Contribuição significativa &
Ineficiência material; oportunidade para análise fundamentalista \\
\(\Delta R^2\) variável no tempo & Contribuição regime-dependente &
Mercados adaptativos (Lo) \\
\end{longtable}

\hypertarget{r2-ajustado}{%
\subsubsection{\texorpdfstring{\(R^2\)
Ajustado}{R\^{}2 Ajustado}}\label{r2-ajustado}}

O \(R^2\) simples aumenta mecanicamente com a adição de regressores,
mesmo que estes não tenham genuíno poder explicativo. O \(R^2\) ajustado
penaliza a adição de variáveis:

\[R^2_{\text{adj}} = 1 - \frac{(1 - R^2)(n - 1)}{n - k - 1}\]

onde \(n\) é o número de observações e \(k\) é o número de regressores
(excluindo o intercepto).

A comparação de \(R^2_{\text{adj}}\) entre modelos informa se a adição
de variáveis melhora genuinamente a explicação ou apenas adiciona
complexidade sem benefício. Se
\(R^2_{\text{adj, Modelo k}} > R^2_{\text{adj, Modelo k-1}}\), a adição
de regressores é justificada.

\hypertarget{crituxe9rios-de-informauxe7uxe3o}{%
\subsubsection{Critérios de
Informação}\label{crituxe9rios-de-informauxe7uxe3o}}

Critérios de informação oferecem enquadramento alternativo --- e mais
rigoroso --- para comparação de modelos, penalizando complexidade de
modo mais severo que o \(R^2\) ajustado.

\textbf{Critério de Informação de Akaike (AIC):}

\[\text{AIC} = 2k - 2\ln(\hat{L})\]

onde \(k\) é o número de parâmetros estimados e \(\hat{L}\) é a
verossimilhança maximizada. Para modelos de regressão linear com erros
gaussianos:

\[\text{AIC} = n \ln\left(\frac{\text{SQR}}{n}\right) + 2k\]

\textbf{Critério de Informação Bayesiano (BIC):}

\[\text{BIC} = k \ln(n) - 2\ln(\hat{L})\]

ou, para regressão linear:

\[\text{BIC} = n \ln\left(\frac{\text{SQR}}{n}\right) + k \ln(n)\]

O BIC penaliza complexidade mais severamente que o AIC (o termo
\(k \ln(n)\) cresce com o tamanho amostral, enquanto \(2k\) é
constante). Em amostras grandes, o BIC tende a selecionar modelos mais
parcimoniosos.

\textbf{Interpretação:} O modelo preferido é aquele com menor AIC (ou
BIC). A diferença
\(\Delta \text{AIC} = \text{AIC}_{\mathcal{M}_k} - \text{AIC}_{\mathcal{M}_{k-1}}\)
indica se o modelo mais complexo é preferível: -
\(\Delta \text{AIC} < 0\): modelo mais complexo é preferível -
\(\Delta \text{AIC} > 0\): modelo mais parcimonioso é preferível -
\(|\Delta \text{AIC}| < 2\): diferença não é substancial

Regras análogas aplicam-se ao BIC, tipicamente com limiares mais
conservadores (\(|\Delta \text{BIC}| < 6\)).

\hypertarget{testes-de-significuxe2ncia-estatuxedstica}{%
\subsubsection{Testes de Significância
Estatística}\label{testes-de-significuxe2ncia-estatuxedstica}}

\textbf{Teste F para Modelos Aninhados:}

O teste F compara formalmente modelos aninhados, testando a hipótese
nula de que os coeficientes adicionais são conjuntamente zero:

\[H_0: \gamma_1 = \gamma_2 = \ldots = \gamma_p = 0\]

A estatística de teste é:

\[F = \frac{(R^2_{\mathcal{M}_k} - R^2_{\mathcal{M}_{k-1}}) / p}{(1 - R^2_{\mathcal{M}_k}) / (n - k - 1)}\]

onde \(p\) é o número de regressores adicionais. Sob \(H_0\), a
estatística segue distribuição \(F(p, n-k-1)\). Rejeição de \(H_0\)
indica que os regressores adicionais contribuem significativamente.

\textbf{Teste t para Coeficientes Individuais:}

A significância individual de cada coeficiente é testada via estatística
t:

\[t_j = \frac{\hat{\gamma}_j}{\text{SE}(\hat{\gamma}_j)}\]

onde \(\text{SE}(\hat{\gamma}_j)\) é o erro-padrão do coeficiente
estimado. Sob \(H_0: \gamma_j = 0\), a estatística segue distribuição
\(t(n-k-1)\). Com erros-padrão robustos, a distribuição assintótica é
normal padrão.

\hypertarget{validauxe7uxe3o-out-of-sample}{%
\subsubsection{Validação
Out-of-Sample}\label{validauxe7uxe3o-out-of-sample}}

Métricas in-sample --- calculadas sobre os mesmos dados usados para
estimação --- podem superestimar o poder preditivo real, especialmente
quando o modelo possui muitos parâmetros relativamente ao tamanho
amostral (\emph{overfitting}). Validação out-of-sample oferece
estimativa mais conservadora e operacionalmente relevante.

\textbf{Divisão Temporal:}

O período amostral é dividido em: - \textbf{Período de treinamento}
(in-sample): Janeiro/2016 a Dezembro/2022 (\textasciitilde7 anos) -
\textbf{Período de teste} (out-of-sample): Janeiro/2023 a Novembro/2025
(\textasciitilde3 anos)

Os modelos são estimados no período de treinamento; o poder preditivo é
avaliado no período de teste. O \(R^2\) out-of-sample
(\(R^2_{\text{OOS}}\)) é calculado como:

\[R^2_{\text{OOS}} = 1 - \frac{\sum_{t \in \text{teste}}(y_t - \hat{y}_t)^2}{\sum_{t \in \text{teste}}(y_t - \bar{y}_{\text{treino}})^2}\]

Note que a média utilizada no denominador é a média do período de
\emph{treinamento}, não do teste --- garantindo que nenhuma informação
futura contamina a avaliação.

\textbf{Validação Cruzada Rolling-Window:}

Para avaliar estabilidade temporal, implementa-se validação cruzada com
janelas móveis:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estima-se o modelo em janela de 252 dias úteis (\textasciitilde1 ano)
\item
  Prevê-se o retorno do dia seguinte
\item
  Desloca-se a janela um dia adiante
\item
  Repete-se o processo
\end{enumerate}

O \(R^2\) rolling é calculado para cada posição da janela, gerando série
temporal de poder explicativo. A variação desta série informa sobre
estabilidade --- ou regime-dependência --- da contribuição informacional
das métricas fundamentalistas.

\hypertarget{muxe9tricas-complementares}{%
\subsubsection{Métricas
Complementares}\label{muxe9tricas-complementares}}

\textbf{Erro Quadrático Médio (MSE) e Raiz do Erro Quadrático Médio
(RMSE):}

\[\text{MSE} = \frac{1}{n}\sum_{t=1}^{n}(y_t - \hat{y}_t)^2\]
\[\text{RMSE} = \sqrt{\text{MSE}}\]

O RMSE tem a vantagem de estar na mesma unidade da variável dependente
(retorno), facilitando interpretação econômica.

\textbf{Erro Absoluto Médio (MAE):}

\[\text{MAE} = \frac{1}{n}\sum_{t=1}^{n}|y_t - \hat{y}_t|\]

O MAE é menos sensível a outliers que o MSE/RMSE.

\textbf{Razão de Sharpe da Estratégia:}

Para avaliar relevância econômica --- não apenas estatística --- dos
resultados, constrói-se estratégia de investimento baseada no score
Q-VAL e calcula-se sua razão de Sharpe:

\[\text{Sharpe} = \frac{E[R_{\text{estratégia}}] - R_f}{\sigma_{\text{estratégia}}}\]

A estratégia assume posição \emph{long} quando Q-VAL indica
\emph{Compra}, posição \emph{cash} quando indica \emph{Neutro}, e
posição \emph{short} (se permitida) ou \emph{cash} quando indica
\emph{Venda}. Comparação com estratégia \emph{buy-and-hold} do Ibovespa
informa sobre valor agregado operacional.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{fontes-de-dados-e-peruxedodo-de-anuxe1lise}{%
\subsection{Fontes de Dados e Período de
Análise}\label{fontes-de-dados-e-peruxedodo-de-anuxe1lise}}

\hypertarget{dados-utilizados}{%
\subsubsection{Dados Utilizados}\label{dados-utilizados}}

Os dados para este trabalho provêm de três fontes complementares:

\textbf{Preços e Retornos:} - Preços de fechamento ajustados de PETR4 e
do índice Ibovespa: API Brapi e B3 - Período: Janeiro/2016 a
Novembro/2025 - Frequência: Diária (dias úteis) - Total aproximado:
2.460 observações

\textbf{Dados Fundamentalistas:} - Demonstrações financeiras
trimestrais: CVM (Comissão de Valores Mobiliários) - Múltiplos e
métricas derivadas: API Brapi - Dados setoriais para benchmarking: bases
públicas complementares

\textbf{Taxa Livre de Risco:} - CDI (Certificado de Depósito
Interbancário): Banco Central do Brasil - Frequência: Diária - Conversão
para taxa diária: \((1 + \text{CDI}_{\text{anual}})^{1/252} - 1\)

\hypertarget{tratamento-de-dados}{%
\subsubsection{Tratamento de Dados}\label{tratamento-de-dados}}

\textbf{Ajuste de Proventos:} Preços são ajustados para dividendos,
juros sobre capital próprio, bonificações e desdobramentos, garantindo
comparabilidade temporal.

\textbf{Dados Faltantes:} Observações com dados faltantes são tratadas
via: - Interpolação linear para lacunas curtas (\textless{} 5 dias) -
Exclusão para lacunas longas - Forward-fill para dados fundamentalistas
(dado trimestral válido até próxima publicação)

\textbf{Winsorização:} Para mitigar efeito de outliers extremos,
retornos são \emph{winsorizados} nos percentis 1 e 99 em análises de
robustez.

\hypertarget{justificativa-do-peruxedodo}{%
\subsubsection{Justificativa do
Período}\label{justificativa-do-peruxedodo}}

A escolha do período Janeiro/2016 a Novembro/2025 justifica-se por:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Ponto de inflexão institucional:} 2016 marca o início do
  período pós-Lava Jato, com reestruturação de governança na Petrobras e
  novo regime de gestão.
\item
  \textbf{Cobertura de ciclos:} O período abrange ciclo completo de
  preços de petróleo (colapso 2015-2016, recuperação 2017-2019, choque
  COVID 2020, alta 2021-2022, normalização 2023-2025).
\item
  \textbf{Eventos estruturais:} Inclui eventos relevantes para teste da
  hipótese --- pandemia, transição energética, autorização da Margem
  Equatorial.
\item
  \textbf{Tamanho amostral:} Aproximadamente 2.460 observações diárias
  fornecem poder estatístico adequado para estimação de múltiplos
  parâmetros.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{reprodutibilidade-computacional}{%
\subsection{Reprodutibilidade
Computacional}\label{reprodutibilidade-computacional}}

A reprodutibilidade constitui princípio metodológico central deste
trabalho. Seguindo o paradigma de pesquisa computacional reproduzível
(Buckheit; Donoho, 1995), todos os dados, procedimentos analíticos e
rotinas de geração de resultados estão disponíveis em repositório
público:

\begin{quote}
\textbf{Repositório:}
\href{https://github.\%20com/lcfranca/unb-cca-mqac}{https://github.com/lcfranca/unb-cca-mqac}
\end{quote}

\hypertarget{estrutura-do-reposituxf3rio}{%
\subsubsection{Estrutura do
Repositório}\label{estrutura-do-reposituxf3rio}}

O repositório organiza-se segundo princípios de separação de
responsabilidades:

\begin{verbatim}
unb-cca-mqac/
+-- data/
|   +-- raw/              # Dados brutos (não processados)
|   +-- processed/        # Dados processados
|   +-- outputs/          # Resultados gerados
|       +-- tables/       # Tabelas em formato LaTeX
|       +-- figures/      # Figuras em formato PDF
+-- src/                  # Código-fonte Python
|   +-- gen_capm.py       # Estimação CAPM
|   +-- gen_qval_scoring.py    # Motor Q-VAL
|   +-- gen_regression_analysis.py  # Análise de regressões
|   +-- utils/            # Funções auxiliares
+-- content/              # Conteúdo textual (Markdown/LaTeX)
+-- notebooks/            # Jupyter notebooks exploratórios
+-- Makefile              # Automação de execução
\end{verbatim}

\hypertarget{princuxedpios-de-reprodutibilidade}{%
\subsubsection{Princípios de
Reprodutibilidade}\label{princuxedpios-de-reprodutibilidade}}

\textbf{Separação Dados-Código-Resultados:} Dados brutos são armazenados
separadamente do código de processamento e dos outputs derivados. Esta
separação permite: - Verificação independente dos procedimentos -
Atualização de dados sem modificação de código - Rastreabilidade
completa do pipeline analítico

\textbf{Versionamento:} Todo código é versionado via Git, com histórico
completo de modificações. Cada resultado pode ser rastreado à versão
específica do código que o gerou.

\textbf{Ambiente Computacional:} Dependências são especificadas em
arquivo \texttt{requirements.txt}, garantindo que o ambiente
computacional possa ser recriado. Versões específicas de bibliotecas são
fixadas para evitar quebras por atualizações.

\textbf{Execução Automatizada:} O \texttt{Makefile} na raiz do
repositório permite execução completa do pipeline analítico via comando
único:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{make}\NormalTok{ all}
\end{Highlighting}
\end{Shaded}

Este comando executa sequencialmente: 1. Coleta e processamento de dados
2. Estimação de modelos 3. Geração de tabelas e figuras 4. Compilação do
documento final

\hypertarget{verificauxe7uxe3o-independente}{%
\subsubsection{Verificação
Independente}\label{verificauxe7uxe3o-independente}}

Pesquisadores interessados em verificar ou estender os resultados podem:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Clonar o repositório:
  \texttt{git\ clone\ https://github.com/lcfranca/unb-cca-mqac.git}
\item
  Instalar dependências: \texttt{pip\ install\ -r\ requirements.\ txt}
\item
  Executar pipeline: \texttt{make\ all}
\item
  Comparar outputs gerados com os reportados no documento
\end{enumerate}

A transparência metodológica permite que usuários ajustem parâmetros
(pesos do Q-VAL, período amostral, métricas incluídas), verifiquem
robustez, e adaptem os modelos a novos contextos ou ativos.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{suxedntese-metodoluxf3gica}{%
\subsection{Síntese Metodológica}\label{suxedntese-metodoluxf3gica}}

A metodologia apresentada operacionaliza a pergunta teórica ---
\emph{métricas fundamentalistas adicionam informação ao mecanismo de
preços? } --- em procedimento empírico testável. O diagrama abaixo
sintetiza o fluxo analítico:

\begin{verbatim}
+-----------------+     +------------------+     +-----------------+
|  Dados Brutos   |---->|   Processamento  |---->|  Motor Q-VAL    |
|  (Preços, DFs)  |     |  (Normalização)  |     |  (Score 0-100)  |
+-----------------+     +------------------+     +--------+--------+
                                                         |
                                                         V
+-----------------+     +------------------+     +-----------------+
|   Comparação    |<----|    Regressões    |<----| Série Temporal  |
|   de Modelos    |     |   (M0->M1->M2->M3)|     |   de Scores     |
+--------+--------+     +------------------+     +-----------------+
         |
         V
+-----------------------------------------------------------------+
|                    Métricas de Avaliação                        |
|  * Delta R2 (contribuição informacional)                        |
|  * AIC/BIC (parcimônia vs. explicação)                          |
|  * Testes F/t (significância estatística)                       |
|  * R2 out-of-sample (poder preditivo genuíno)                   |
+-----------------------------------------------------------------+
\end{verbatim}

Os resultados desta análise permitirão conclusões sobre:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Magnitude da contribuição:} Qual o \(\Delta R^2\) atribuível
  às métricas fundamentalistas?
\item
  \textbf{Significância estatística:} A contribuição é estatisticamente
  distinguível de zero?
\item
  \textbf{Relevância econômica:} A contribuição traduz-se em capacidade
  preditiva operacional?
\item
  \textbf{Estabilidade temporal:} A contribuição é estável ou varia
  entre regimes?
\item
  \textbf{Parcimônia:} O ganho explicativo justifica a complexidade
  adicional?
\end{enumerate}

As respostas a estas questões informarão a discussão teórica sobre
eficiência informacional do mercado brasileiro com respeito a informação
fundamentalista pública --- contribuindo para o debate entre visões
hayekiana, EMH, Grossman-Stiglitz e mercados adaptativos, com foco
empírico no caso Petrobras.

\hypertarget{resultados-empuxedricos}{%
\section{4. Resultados Empíricos}\label{resultados-empuxedricos}}

A análise empírica revela uma estrutura informacional complexa e
dinâmica para as ações da Petrobras (PETR4). Os resultados são
apresentados seguindo uma lógica incremental: partindo do diagnóstico
estatístico básico (4.1), avançando para modelos lineares de
precificação (4.2), analisando a dinâmica temporal da informação (4.3),
e culminando em abordagens não-lineares e adaptativas (4.4 e 4.5).

\hypertarget{diagnuxf3stico-inicial-e-estatuxedsticas-descritivas}{%
\subsection{4.1. Diagnóstico Inicial e Estatísticas
Descritivas}\label{diagnuxf3stico-inicial-e-estatuxedsticas-descritivas}}

A Tabela \ref{tab:desc_stats} apresenta as estatísticas descritivas dos
retornos diários e das métricas fundamentalistas. Observa-se que a
distribuição dos retornos da PETR4 exibe desvios significativos da
normalidade, com curtose excessiva (18.10) e assimetria negativa
(-1.39). Este padrão de ``caudas gordas'' sugere que modelos baseados em
premissas gaussianas estritas podem subestimar a probabilidade de
eventos extremos, justificando a exploração posterior de modelos de
mudança de regime.

\input{data/outputs/tables/estatisticas_descritivas.tex}

Adicionalmente, a análise dinâmica do risco sistemático (Figura
\ref{fig:beta_evolution}) revela que o Beta do ativo não é um parâmetro
estrutural fixo. A flutuação do coeficiente ao longo do tempo ---
oscilando entre regimes de alta e baixa correlação com o índice de
mercado --- corrobora a crítica à estacionariedade implícita no CAPM
incondicional.

\begin{figure}
\hypertarget{fig:beta_evolution}{%
\centering
\includegraphics{images/beta_evolution.pdf}
\caption{Evolução Dinâmica do Beta (Janela Móvel de 252
dias).}\label{fig:beta_evolution}
}
\end{figure}

\hypertarget{eficiuxeancia-linear-e-o-valor-da-informauxe7uxe3o-fundamentalista}{%
\subsection{4.2. Eficiência Linear e o Valor da Informação
Fundamentalista}\label{eficiuxeancia-linear-e-o-valor-da-informauxe7uxe3o-fundamentalista}}

A investigação sobre a eficiência informacional inicia-se com o teste da
Hipótese dos Mercados Eficientes na forma semi-forte. A Tabela
\ref{tab:capm_results} reporta a estimação do modelo base (M0 - CAPM). O
coeficiente de determinação (\(R^2\)) de 0.55 indica que aproximadamente
45\% da variância dos retornos permanece inexplicada pelo fator de
mercado, abrindo espaço teórico para fatores adicionais. O Alfa de
Jensen estimado não é estatisticamente distinto de zero, sugerindo que,
na média incondicional, não há retornos anormais inexplicados pelo risco
sistemático.

\input{data/outputs/tables/resultados_capm.tex}

A introdução de vetores de informação fundamentalista (Modelos M1 a M3)
visa capturar essa variância residual. A Tabela \ref{tab:aic_bic}
compara os modelos via critérios de informação. Observa-se que o Modelo
M2 (Multifatorial Desagregado) minimiza o critério AIC, sugerindo que a
decomposição dos fundamentos em dimensões de Valor, Qualidade e Risco
adiciona conteúdo informacional relevante. Contudo, o critério BIC, que
penaliza mais severamente a complexidade, favorece o modelo parcimonioso
(M0), indicando que o sinal fundamentalista, embora presente, compete
com um nível elevado de ruído estocástico.

\input{data/outputs/tables/criterios_informacao.tex}

A Tabela \ref{tab:model_comparison} confronta a performance
\emph{in-sample} com a capacidade preditiva \emph{out-of-sample}. A
degradação do \(R^2\) no período de teste (de \textasciitilde0.60 para
\textasciitilde0.12) é consistente com a literatura de previsibilidade
de retornos: relações estatísticas tendem a enfraquecer fora da amostra
de treinamento, evidenciando a natureza adaptativa e não-estacionária do
processo gerador de dados.

\input{data/outputs/tables/comparacao_modelos.tex}

\hypertarget{dinuxe2mica-temporal-e-decaimento-do-sinal}{%
\subsection{4.3. Dinâmica Temporal e Decaimento do
Sinal}\label{dinuxe2mica-temporal-e-decaimento-do-sinal}}

A eficácia da informação fundamentalista não é uniforme no tempo. A
Figura \ref{fig:decay} e a Tabela \ref{tab:decay} ilustram o decaimento
do \emph{Information Coefficient} (IC) após a divulgação dos
demonstrativos financeiros. O poder preditivo é máximo na janela
imediata (0-5 dias), com IC de 61\%, e decai rapidamente nas semanas
subsequentes. Este perfil de decaimento corrobora a visão hayekiana de
que o mercado é um mecanismo processual de descoberta de preços: a
incorporação da informação não é instantânea, mas ocorre através de um
processo de arbitragem que consome a vantagem informacional ao longo do
tempo.

\begin{figure}
\hypertarget{fig:decay}{%
\centering
\includegraphics{images/information_decay_curve.pdf}
\caption{Curva de Decaimento Informacional: Persistência do Sinal
Fundamentalista.}\label{fig:decay}
}
\end{figure}

\input{data/outputs/tables/tab_decaimento_informacional.tex}

\hypertarget{a-fronteira-nuxe3o-linear-e-adaptativa-m4-e-m5}{%
\subsection{4.4. A Fronteira Não-Linear e Adaptativa (M4 e
M5)}\label{a-fronteira-nuxe3o-linear-e-adaptativa-m4-e-m5}}

A limitação dos modelos lineares em capturar a complexidade do processo
de precificação motiva a adoção de abordagens não-lineares. A aplicação
de técnicas de \emph{Machine Learning} e modelagem de regimes permite
relaxar as restrições de linearidade e estacionariedade.

\hypertarget{determinantes-nuxe3o-lineares-xgboost}{%
\subsubsection{4.4.1. Determinantes Não-Lineares
(XGBoost)}\label{determinantes-nuxe3o-lineares-xgboost}}

Para capturar não-linearidades, utilizamos um modelo de \emph{Gradient
Boosting} (XGBoost). A análise de importância de atributos via SHAP
Values (Figura \ref{fig:shap}) revela a hierarquia de fatores que movem
o preço. Diferentemente de uma regressão linear que impõe coeficientes
fixos, o modelo não-linear identifica que o impacto de variáveis
macroeconômicas (como o Risco País/EMBI) e microeconômicas (como
métricas de Valor) é condicional ao estado das outras variáveis.

\begin{figure}
\hypertarget{fig:shap}{%
\centering
\includegraphics{images/ml_feature_importance_beeswarm.pdf}
\caption{SHAP Beeswarm Plot: Impacto das variáveis nos retornos futuros
(5 dias). Pontos à direita indicam contribuição positiva para o
retorno.}\label{fig:shap}
}
\end{figure}

A Figura \ref{fig:interaction} ilustra a superfície de resposta entre
Beta e Retorno do Brent. A curvatura da superfície demonstra que a
sensibilidade do ativo ao preço do petróleo não é constante, mas é
amplificada em regimes de alto risco sistemático (Beta elevado). Esta
interação não-linear explica por que modelos de fator único falham em
momentos de estresse de mercado.

\begin{figure}
\hypertarget{fig:interaction}{%
\centering
\includegraphics{images/interaction_surface_2d.pdf}
\caption{Superfície de Interação: Retorno Esperado (eixo Z/Cor) em
função do Beta e do Petróleo.}\label{fig:interaction}
}
\end{figure}

\hypertarget{dinuxe2mica-de-regimes-markov-switching}{%
\subsubsection{4.4.2. Dinâmica de Regimes (Markov
Switching)}\label{dinuxe2mica-de-regimes-markov-switching}}

A aplicação do modelo \emph{Markov Switching} (MS-DR) identificou dois
regimes de mercado distintos e persistentes, corroborando a Hipótese dos
Mercados Adaptativos. A Figura \ref{fig:regime_map} apresenta a evolução
do preço do ativo condicionada à probabilidade de regime.

\begin{figure}
\hypertarget{fig:regime_map}{%
\centering
\includegraphics{images/markov_regime_map.pdf}
\caption{Mapa de Regimes de Mercado: A cor da linha indica a
probabilidade de regime de alta volatilidade (Vermelho) vs.~baixa
volatilidade (Verde).}\label{fig:regime_map}
}
\end{figure}

Os regimes identificados apresentam características estruturais
divergentes: * \textbf{Regime 0 (Calmaria/Bull):} Caracterizado por
baixa variância (\(\sigma^2 \approx 3.2\)) e \emph{drift} positivo. Este
regime tende a prevalecer em períodos de estabilidade macroeconômica e
clareza regulatória, onde a informação fundamentalista tem maior peso
relativo. * \textbf{Regime 1 (Crise/Bear):} Caracterizado por variância
explosiva (\(\sigma^2 \approx 47.8\)) e \emph{drift} negativo. Este
regime captura choques exógenos e incertezas políticas, momentos em que
a volatilidade (ruído) domina o sinal fundamentalista.

\hypertarget{suxedntese-avaliauxe7uxe3o-econuxf4mica}{%
\subsection{4.5. Síntese: Avaliação
Econômica}\label{suxedntese-avaliauxe7uxe3o-econuxf4mica}}

Para testar a utilidade econômica desses modelos sob a ótica de
Grossman-Stiglitz --- isto é, se o custo da informação é compensado por
retornos superiores ---, simulamos uma estratégia de negociação baseada
nos sinais do modelo XGBoost comparada à estratégia passiva (\emph{Buy
\& Hold}). A Figura \ref{fig:equity} apresenta as curvas de capital
resultantes.

\begin{figure}
\hypertarget{fig:equity}{%
\centering
\includegraphics{images/ml_comparison_equity_curve.pdf}
\caption{Backtest Comparativo: Estratégia ML vs.~Buy \& Hold
(2021-2025).}\label{fig:equity}
}
\end{figure}

A estratégia baseada em ML demonstrou capacidade de gerar retornos
ajustados ao risco superiores, primariamente através da proteção de
capital em períodos de alta volatilidade (Regime 1). Este resultado
oferece evidência favorável à Hipótese dos Mercados Adaptativos:
ineficiências temporárias e previsíveis emergem e podem ser exploradas
por modelos capazes de adaptar-se a mudanças de regime, validando a
premissa de que a análise fundamentalista estruturada adiciona valor
econômico marginal, ainda que este valor seja condicional ao estado do
mercado.

\hypertarget{discussuxe3o}{%
\section{5. Discussão}\label{discussuxe3o}}

Os resultados empíricos apresentados oferecem uma resposta nuançada à
pergunta central deste trabalho: a análise fundamentalista estruturada
adiciona informação ao processo de precificação, mas essa contribuição
não é constante, linear ou incondicional. A evidência aponta para um
mercado que opera sob a lógica da Hipótese dos Mercados Adaptativos
(AMH), alternando entre regimes de eficiência e ineficiência em resposta
a mudanças ambientais.

\hypertarget{a-ilusuxe3o-da-linearidade-e-a-natureza-do-ruuxeddo}{%
\subsection{5.1. A Ilusão da Linearidade e a Natureza do
Ruído}\label{a-ilusuxe3o-da-linearidade-e-a-natureza-do-ruuxeddo}}

A divergência entre os critérios de informação --- com o AIC favorecendo
o modelo multifatorial (M2) e o BIC favorecendo o modelo parcimonioso
(M0) --- revela a tensão central na precificação de ativos: a distinção
entre sinal e ruído. O modelo linear clássico captura a estrutura média
de correlação, onde o Beta explica a maior parte da variância. A
informação fundamentalista (Valor, Qualidade) existe e é detectável
(reduz o AIC), mas sua magnitude é frequentemente ofuscada pela
volatilidade estocástica do mercado (penalizada pelo BIC).

O colapso do poder explicativo fora da amostra (\(R^2\) caindo de 0.60
para 0.12) sugere que as relações lineares estimadas \emph{ex-ante} são
instáveis. Isso corrobora a crítica da Economia da Complexidade: assumir
que a elasticidade do preço em relação aos fundamentos é constante (um
\(\beta\) fixo) é uma simplificação excessiva. A análise de superfície
de resposta (Figura \ref{fig:interaction}) demonstra que o mercado
precifica o ``Valor'' de forma diferente dependendo do nível de
``Risco''. Em momentos de estresse (Beta alto), o mercado ignora
fundamentos de qualidade e reage primordialmente a fatores macro (Risco
País, Petróleo), um comportamento de ``fuga para a liquidez'' que
modelos lineares interpretam como erro de previsão.

\hypertarget{eficiuxeancia-adaptativa-o-mercado-como-sistema-de-regimes}{%
\subsection{5.2. Eficiência Adaptativa: O Mercado como Sistema de
Regimes}\label{eficiuxeancia-adaptativa-o-mercado-como-sistema-de-regimes}}

A identificação de dois regimes de volatilidade distintos via Markov
Switching oferece a explicação teórica mais robusta para os achados. O
mercado não é ``eficiente'' ou ``ineficiente'' em abstrato; ele exibe
eficiência variável dependendo do estado.

\begin{itemize}
\tightlist
\item
  \textbf{No Regime 0 (Calmaria),} a volatilidade é baixa e o mercado
  aproxima-se da eficiência hayekiana: os preços incorporam gradualmente
  as informações fundamentais, e o \emph{Information Coefficient} é
  positivo.
\item
  \textbf{No Regime 1 (Crise),} a volatilidade explode e a eficiência
  informacional colapsa. O ruído domina o sinal, e o comportamento de
  manada (\emph{herding}) prevalece sobre a análise racional.
\end{itemize}

Este achado valida a proposição de Lo (2004): a eficiência é uma
característica dinâmica. Estratégias fundamentalistas que funcionam no
Regime 0 podem falhar catastroficamente no Regime 1 se não incorporarem
mecanismos de adaptação ao risco.

\hypertarget{o-paradoxo-de-grossman-stiglitz-revisitado}{%
\subsection{5.3. O Paradoxo de Grossman-Stiglitz
Revisitado}\label{o-paradoxo-de-grossman-stiglitz-revisitado}}

O teste econômico da estratégia baseada em Machine Learning lança luz
sobre o Paradoxo de Grossman-Stiglitz. A estratégia gerou retorno
superior ao \emph{benchmark} (Alpha positivo), mas esse retorno não
adveio de uma capacidade mágica de prever cada movimento de preço. Pelo
contrário, a vantagem adveio da capacidade de \emph{evitar} perdas nos
regimes de alta volatilidade.

Isso sugere uma reinterpretação do ``custo da informação''. O
investimento em análise fundamentalista sofisticada (Q-VAL + ML) é
compensado não por lucros fáceis em mercados de alta, mas pela proteção
de capital em mercados de baixa. A ineficiência que permite o lucro não
é uma falha de mercado, mas um prêmio pela capacidade de processar
informações complexas e não-lineares que o investidor médio (linear)
ignora.

\hypertarget{implicauxe7uxf5es-para-a-avaliauxe7uxe3o-de-ativos-em-mercados-emergentes}{%
\subsection{5.4. Implicações para a Avaliação de Ativos em Mercados
Emergentes}\label{implicauxe7uxf5es-para-a-avaliauxe7uxe3o-de-ativos-em-mercados-emergentes}}

Para o caso específico da Petrobras (PETR4), os resultados destacam a
primazia dos fatores macroeconômicos e de risco sistemático sobre os
fundamentos idiossincráticos no curto prazo. A alta curtose e a
importância dominante do Risco País (EMBI) e do Petróleo (Brent) indicam
que, para ativos em mercados emergentes, a ``Qualidade'' e o ``Valor''
são condições necessárias, mas não suficientes, para a performance. O
mercado exige um prêmio de risco variável para carregar o ativo, e esse
prêmio flutua drasticamente com o ciclo político e econômico.

Em suma, a análise fundamentalista adiciona valor, todavia, esse valor é
estritamente condicional ao regime de mercado vigente. O investidor que
ignora a dinâmica de regimes e confia cegamente em múltiplos estáticos
(como P/L histórico) está fadado a subestimar os riscos de cauda. A
integração de métricas de qualidade com modelos adaptativos de risco
representa, portanto, a fronteira da prática de \emph{valuation}
rigorosa.

\hypertarget{conclusuxe3o}{%
\section{6. Conclusão}\label{conclusuxe3o}}

Este estudo investigou a estrutura informacional do mercado de capitais
brasileiro através de uma análise empírica da Petrobras (PETR4),
confrontando a Hipótese dos Mercados Eficientes com a perspectiva dos
Mercados Adaptativos. A construção e teste do motor Q-VAL permitiram
isolar a contribuição marginal da informação fundamentalista sobre o
modelo de mercado tradicional.

Os resultados indicam que a eficiência de mercado não é um estado
binário, mas um processo dinâmico e dependente de regime. Enquanto
modelos lineares (CAPM e Multifatoriais) capturam a estrutura média de
retornos, eles falham em explicar a dinâmica de preços em períodos de
estresse, onde a não-linearidade e a interação entre variáveis
macroeconômicas tornam-se dominantes. A superioridade do modelo de
\emph{Machine Learning} e a identificação de regimes de volatilidade via
\emph{Markov Switching} confirmam que o mercado alterna entre períodos
de coordenação eficiente e períodos de ruído comportamental.

Conclui-se que a análise fundamentalista estruturada possui valor
econômico, validando a premissa de Grossman-Stiglitz; contudo, sua
eficácia não deriva da mera disponibilidade de dados, mas da
sofisticação do processamento. A vantagem informacional reside na
capacidade de navegar a complexidade e a não-estacionariedade,
transformando dados brutos em sinal adaptativo. Para o investidor em
mercados emergentes, a lição é clara: a busca por ``Alpha'' não reside
apenas na identificação de ativos baratos, mas na compreensão dos
regimes de risco que governam a precificação desses ativos.

Pesquisas futuras podem expandir esta metodologia para uma cesta
diversificada de ativos, testar arquiteturas de \emph{Deep Learning}
(como LSTMs) para captura de dependências temporais de longo prazo, e
incorporar dados não-estruturados (análise de sentimento de notícias)
para enriquecer o conjunto informacional do motor Q-VAL, avançando na
fronteira da \emph{Natural Language Processing} aplicada a finanças.

\hypertarget{referuxeancias}{%
\section*{Referências}\label{referuxeancias}}
\addcontentsline{toc}{section}{Referências}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{1}
\leavevmode\vadjust pre{\hypertarget{ref-arthurBoundedRationalityElArol1994}{}}%
ARTHUR, W. Brian. Inductive Reasoning and Bounded Rationality.
\textbf{American Economic Review}, v. 84, n. 2, p. 406--411, 1994.

\leavevmode\vadjust pre{\hypertarget{ref-arthurComplexityEconomy2014}{}}%
ARTHUR, W. Brian. \textbf{Complexity and the Economy}.
\emph{{[}S.l.{]}}: Oxford University Press, 2014.

\leavevmode\vadjust pre{\hypertarget{ref-arthurComplexityEconomics2021}{}}%
ARTHUR, W. Brian. Foundations of Complexity Economics. \textbf{Nature
Reviews Physics}, v. 3, p. 136--145, 2021.

\leavevmode\vadjust pre{\hypertarget{ref-asnessSizeValueQuality2014}{}}%
ASNESS, Clifford S.; FRAZZINI, Andrea; PEDERSEN, Lasse Heje. Quality
Minus Junk. \textbf{Review of Accounting Studies}, v. 24, n. 1, p.
34--112, a2019.

\leavevmode\vadjust pre{\hypertarget{ref-asnessSizeValueQuality2019}{}}%
ASNESS, Clifford S.; FRAZZINI, Andrea; PEDERSEN, Lasse Heje. Quality
Minus Junk. \textbf{Review of Accounting Studies}, v. 24, n. 1, p.
34--112, b2019.

\leavevmode\vadjust pre{\hypertarget{ref-asnesValueMomentumEverywhere2013}{}}%
ASNESS, Clifford S.; MOSKOWITZ, Tobias J.; PEDERSEN, Lasse Heje. Value
and Momentum Everywhere. \textbf{The Journal of Finance}, v. 68, n. 3,
p. 929--985, 2013.

\leavevmode\vadjust pre{\hypertarget{ref-bikhchandaniTheoryFadsCustom1992}{}}%
BIKHCHANDANI, Sushil; HIRSHLEIFER, David; WELCH, Ivo. A Theory of Fads,
Fashion, Custom, and Cultural Change as Informational Cascades.
\textbf{Journal of Political Economy}, v. 100, n. 5, p. 992--1026, 1992.

\leavevmode\vadjust pre{\hypertarget{ref-shimirovichSocialMediaStock2011}{}}%
BOLLEN, Johan; MAO, Huina; ZENG, Xiaojun. Twitter Mood Predicts the
Stock Market. \textbf{Journal of Computational Science}, v. 2, n. 1, p.
1--8, 2011.

\leavevmode\vadjust pre{\hypertarget{ref-buckheitWaveLab1995}{}}%
BUCKHEIT, Jonathan B.; DONOHO, David L. WaveLab and Reproducible
Research. \textbf{Wavelets and Statistics}, p. 55--81, 1995.

\leavevmode\vadjust pre{\hypertarget{ref-colinjaegerEfficientMarketHypothesis2020}{}}%
COLIN-JAEGER, Nathanaël; DELCEY, Thomas. When Efficient Market
Hypothesis Meets Hayek on Information: Beyond a Methodological Reading.
\textbf{Journal of Economic Methodology}, v. 27, n. 2, p. 97--116, 2020.

\leavevmode\vadjust pre{\hypertarget{ref-famaEfficientCapitalMarkets1970}{}}%
FAMA, Eugene F. Efficient Capital Markets: A Review of Theory and
Empirical Work. \textbf{The Journal of Finance}, v. 25, n. 2, p.
383--417, 1970.

\leavevmode\vadjust pre{\hypertarget{ref-fama1998MarketEfficiencyLongterm}{}}%
FAMA, Eugene F. Market Efficiency, Long-Term Returns, and Behavioral
Finance. \textbf{Journal of Financial Economics}, v. 49, n. 3, p.
283--306, 1998.

\leavevmode\vadjust pre{\hypertarget{ref-famaCommonRiskFactors1993}{}}%
FAMA, Eugene F.; FRENCH, Kenneth R. Common Risk Factors in the Returns
on Stocks and Bonds. \textbf{Journal of Financial Economics}, v. 33, n.
1, p. 3--56, 1993.

\leavevmode\vadjust pre{\hypertarget{ref-famaFivefactorAssetPricing2015}{}}%
FAMA, Eugene F.; FRENCH, Kenneth R. A Five-Factor Asset Pricing Model.
\textbf{Journal of Financial Economics}, v. 116, n. 1, p. 1--22, 2015.

\leavevmode\vadjust pre{\hypertarget{ref-glostenBidAskSpread1985}{}}%
GLOSTEN, Lawrence R.; MILGROM, Paul R. Bid, Ask and Transaction Prices
in a Specialist Market with Heterogeneously Informed Traders.
\textbf{Journal of Financial Economics}, v. 14, n. 1, p. 71--100, 1985.

\leavevmode\vadjust pre{\hypertarget{ref-grahamSecurityAnalysis1934}{}}%
GRAHAM, Benjamin; DODD, David L. \textbf{Security Analysis}.
\emph{{[}S.l.{]}}: McGraw-Hill, 1934.

\leavevmode\vadjust pre{\hypertarget{ref-grayQuantitativeValuePractitioners2012}{}}%
GRAY, Wesley R.; CARLISLE, Tobias E. \textbf{Quantitative Value: A
Practitioner's Guide to Automating Intelligent Investment and
Eliminating Behavioral Errors}. \emph{{[}S.l.{]}}: Wiley, 2012.

\leavevmode\vadjust pre{\hypertarget{ref-grossmanImpossibilityInformationallyEfficient1980}{}}%
GROSSMAN, Sanford J.; STIGLITZ, Joseph E. On the Impossibility of
Informationally Efficient Markets. \textbf{American Economic Review}, v.
70, n. 3, p. 393--408, 1980.

\leavevmode\vadjust pre{\hypertarget{ref-gruberAnotherPuzzleGrowth1996}{}}%
GRUBER, Martin J. Another Puzzle: The Growth in Actively Managed Mutual
Funds. \textbf{The Journal of Finance}, v. 51, n. 3, p. 783--810, 1996.

\leavevmode\vadjust pre{\hypertarget{ref-guEmpiricalAssetPricing2020}{}}%
GU, Shihao; KELLY, Bryan; XIU, Dacheng. Empirical Asset Pricing via
Machine Learning. \textbf{The Review of Financial Studies}, v. 33, n. 5,
p. 2223--2273, 2020.

\leavevmode\vadjust pre{\hypertarget{ref-harveyReplicationCrossSection2016}{}}%
HARVEY, Campbell R.; LIU, Yan; ZHU, Heqing. and the Cross-Section of
Expected Returns. \textbf{The Review of Financial Studies}, v. 29, n. 1,
p. 5--68, 2016.

\leavevmode\vadjust pre{\hypertarget{ref-hayekUseKnowledgeSociety1945}{}}%
HAYEK, Friedrich A. The Use of Knowledge in Society. \textbf{American
Economic Review}, v. 35, n. 4, p. 519--530, 1945.

\leavevmode\vadjust pre{\hypertarget{ref-hellwigAggregatingInformationPredict2009}{}}%
HELLWIG, Christian; VELDKAMP, Laura. Knowing What Others Know:
Coordination Motives in Information Acquisition. \textbf{The Review of
Economic Studies}, v. 76, n. 1, p. 223--251, 2009.

\leavevmode\vadjust pre{\hypertarget{ref-hirshleifer2023SocialContagion}{}}%
HIRSHLEIFER, David; LO, Andrew W.; ZHANG, Ruixun. Social Contagion and
the Survival of Diverse Investment Styles. \textbf{Journal of Economic
Dynamics and Control}, v. 154, p. 104710, 2023.

\leavevmode\vadjust pre{\hypertarget{ref-jaaborImpactInsiderTrading2004}{}}%
JAFFE, Jeffrey F. Special Information and Insider Trading. \textbf{The
Journal of Business}, v. 47, n. 3, p. 410--428, 1974.

\leavevmode\vadjust pre{\hypertarget{ref-jegadeeshReturnsBuyingWinners1993}{}}%
JEGADEESH, Narasimhan; TITMAN, Sheridan. Returns to Buying Winners and
Selling Losers: Implications for Stock Market Efficiency. \textbf{The
Journal of Finance}, v. 48, n. 1, p. 65--91, 1993.

\leavevmode\vadjust pre{\hypertarget{ref-kucharCompetitionSociallyExtended2025}{}}%
KUCHAR, Pavel. Competition as Socially Extended Cognition.
\textbf{Working Paper}, 2025.

\leavevmode\vadjust pre{\hypertarget{ref-kyleInformedSpeculationImperfect1989}{}}%
KYLE, Albert S. Informed Speculation with Imperfect Competition.
\textbf{The Review of Economic Studies}, v. 56, n. 3, p. 317--355, 1989.

\leavevmode\vadjust pre{\hypertarget{ref-leBaron2006AgentBasedComputational}{}}%
LEBARON, Blake. Agent-Based Computational Finance. \emph{In}:
TESFATSION, Leigh; JUDD, Kenneth L. (Orgs.). \textbf{Handbook of
Computational Economics}. \emph{{[}S.l.{]}}: Elsevier, 2006. v. 2 p.
1187--1233.

\leavevmode\vadjust pre{\hypertarget{ref-loAdaptiveMarketsHypothesis2004}{}}%
LO, Andrew W. The Adaptive Markets Hypothesis. \textbf{Journal of
Portfolio Management}, v. 30, n. 5, p. 15--29, 2004.

\leavevmode\vadjust pre{\hypertarget{ref-loAdaptiveMarketsHypothesis2024}{}}%
LO, Andrew W.; ZHANG, Ruixun. \textbf{The Adaptive Markets Hypothesis:
An Evolutionary Approach to Understanding Financial System Dynamics}.
\emph{{[}S.l.{]}}: Oxford University Press, 2024.

\leavevmode\vadjust pre{\hypertarget{ref-mcleanDoesAcademicResearch2016}{}}%
MCLEAN, R. David; PONTIFF, Jeffrey. Does Academic Research Destroy Stock
Return Predictability? \textbf{The Journal of Finance}, v. 71, n. 1, p.
5--32, 2016.

\leavevmode\vadjust pre{\hypertarget{ref-novy-marxOtherSideValue2013}{}}%
NOVY-MARX, Robert. The Other Side of Value: The Gross Profitability
Premium. \textbf{Journal of Financial Economics}, v. 108, n. 1, p.
1--28, 2013.

\leavevmode\vadjust pre{\hypertarget{ref-pastushkovEvolutionaryModelFinancial2024}{}}%
PASTUSHKOV, Ivan. An Evolutionary Model of Financial Market Efficiency
with Costly Information. \textbf{HSE Economic Journal}, v. 28, n. 4, p.
508--534, 2024.

\leavevmode\vadjust pre{\hypertarget{ref-sorosAlchemyFinance1987}{}}%
SOROS, George. \textbf{The Alchemy of Finance: Reading the Mind of the
Market}. \emph{{[}S.l.{]}}: Simon \& Schuster, 1987.

\leavevmode\vadjust pre{\hypertarget{ref-stiglitzKosenkoEconomicsInformation2024}{}}%
STIGLITZ, Joseph E.; KOSENKO, Andrew. \textbf{The Economics of
Information}. \emph{{[}S.l.{]}}: National Bureau of Economic Research,
2024.

\leavevmode\vadjust pre{\hypertarget{ref-verrecchiaInformationAcquisitionCapital1982}{}}%
VERRECCHIA, Robert E. Information Acquisition in a Noisy Rational
Expectations Economy. \textbf{Econometrica}, v. 50, n. 6, p. 1415--1430,
1982.

\end{CSLReferences}

%% --------------------------------------------------------------------------
%% BIBLIOGRAFIA
%% --------------------------------------------------------------------------
\newpage
\bibliography{references.bib}

\end{document}
